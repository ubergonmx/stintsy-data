{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npHU9aaEQaDa"
   },
   "source": [
    "Name: Aaron Palpallatoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLyPn26tQaDb"
   },
   "source": [
    "Section: S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61kaUAOSQaDd"
   },
   "source": [
    "# Regularized Linear Regression Exercise\n",
    "\n",
    "**In this exercise you will:**\n",
    "- Extend your linear regression model to produce non-linear regression lines/curve (sometimes referred to as polynomial regression)\n",
    "- Include regularization to reduce over-fitting (more specifically implement lasso and ridge regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZP2B4rf5QaEE"
   },
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with \"A: \" on them. The answer must strictly consume one line only.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* There are commented markdown cells that have crumbs. Do not delete them or separate them from the cell originally directly below it.  \n",
    "* You may add new cells for \"scrap work\" as long as the crumbs are not separated from the cell below it.\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You are expected to understand the data set loading and processing separately from this class.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1649926271673,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "JMFzBpYWQaEF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNzz3HdYQaEH"
   },
   "source": [
    "## Generate Data\n",
    "Generate some sample data points, and use a sine function over `x` for the `y` values (with random noise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1649926306853,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "oPd8f19YmWS-"
   },
   "outputs": [],
   "source": [
    "def generate_sample_data(pts):\n",
    "    x = np.random.uniform(-1.0,1.0, pts)\n",
    "    y = np.sin(6 * x) + np.random.randn(pts) * 0.5\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649926307414,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "mFxAgPbAQaEI",
    "outputId": "fdae14e1-c62a-4253-b441-6bffa68cfd49",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pts = 20\n",
    "np.random.seed(1)\n",
    "over_x, over_y = generate_sample_data(pts)\n",
    "\n",
    "plt.scatter(over_x,over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoJsekelQaEL"
   },
   "source": [
    "## Bias-variance trade-off\n",
    "\n",
    "### Plotting the optimal model\n",
    "\n",
    "Look at the figure above. The code who generated the point of that graph follows a sine function, so we know exactly what the best looking model for the data above should look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1649826665653,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "rBNkLCf7QaEN",
    "outputId": "b18e6039-8398-4fb0-ed5e-8ae97fb5a408",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(over_x,over_y)\n",
    "\n",
    "x_range = np.arange(-1, 1, 0.01)\n",
    "y_range = np.sin(6 * x_range)\n",
    "plt.plot(x_range, y_range, 'k--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyOwP350QaEO"
   },
   "source": [
    "The black dotted line is the target function `f(x)` that generated the red dots (after some additional errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7w8xvgTQaEQ"
   },
   "source": [
    "Take note that in real world scenarios, we are talking about hundreds to millions of features. So, the ability to \"look at the data and just draw the curve that feels right\" is a luxury we can enjoy now with this small dataset. With real world data, this is not the case, and we can most likely cannot visualize all features altogether in one graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zpydp7QmWTE"
   },
   "source": [
    "### Plotting a plain analytical solution model \n",
    "Plotting the analytical solution/closed form/normal equation model \n",
    "\n",
    "To do this, use the function `np.polyfit()` which is similar to the closed form equation from the last notebook. We won't do any feature transformation yet, i.e., just degree == 1. Assign the return value to variable `weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xipri1wQaET",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHYoOU-YmWTG"
   },
   "source": [
    "The function `np.poly1d()` returns a function that will perform the feature transform for us given the weights. Assign the return value to variable `fit_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_N7VWwcXmWTG"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp0oYS1UmWTH"
   },
   "source": [
    "`y_range` uses `fit_fn` to transform the data prior to getting the score/predictions (no effect for now because it is still degree=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uckXOqFPmWTI"
   },
   "outputs": [],
   "source": [
    "x_range = np.arange(np.min(over_x), np.max(over_x), 0.01)\n",
    "y_range = fit_fn(x_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDVoLDNqmWTI"
   },
   "source": [
    "Then, we finally plot the analytical solution model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1649826665656,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "1ooEehpRmWTJ",
    "outputId": "aab6e476-bd7c-4b6d-f1e1-ce05504c4c04"
   },
   "outputs": [],
   "source": [
    "plt.plot(x_range, y_range, 'k')\n",
    "plt.scatter(over_x, over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYrPH1NcQaEU"
   },
   "source": [
    "It is clear that this line, no matter which way you change the slope to another direction, will still not do a great job. This is because it is simply a line that we are forcing to model a sine functiom. We call this underfitting because we are not fitting the model to the data well. We also say that this model has a high bias, because our estimate is far off the actual data. Look at the chart below at the far left:\n",
    "\n",
    "<img width=\"700px\" src=\"https://imgur.com/mJLDfBs.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzRENmcsQaEV"
   },
   "source": [
    "One way to remedy this is to increase the order or degree of our hypothesis function through feature transformation. With polynomial feature transformation, we can generate more complex functions, and get a better fit of our dataset.\n",
    "\n",
    "Let's try to do the same thing, and increase the polynomial degree complexity of our model. \n",
    "\n",
    "\n",
    "We normally do this by adding features based on our original features. The `np.polyfit()` function has a way to increase the polynomial degree on its own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tRNT98tmWTL"
   },
   "source": [
    "### Plotting a more complex analytical solution model \n",
    "\n",
    "This time, let's perform feature transform in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnLfI48hmWTL"
   },
   "outputs": [],
   "source": [
    "x_range = np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature transform to our data by using the function `np.polyfit()` and setting the degree to `3`. Assign the return value to variable `weights`. Then, assign the feature transform function to variable `fit_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1160,
     "status": "ok",
     "timestamp": 1649826666792,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "2zLV-AUfrWeW",
    "outputId": "580fa58c-04b4-4a6e-9dcc-6dcd81f3dba8"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = fit_fn(x_range)\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "plt.scatter(over_x, over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature transform to our data by using the function `np.polyfit()` and setting the degree to `5`. Assign the return value to variable `weights`. Then, assign the feature transform function to variable `fit_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1649826666792,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "AR4xdTU1sK50",
    "outputId": "f22f0252-2e19-4006-f46d-05fde78d711e"
   },
   "outputs": [],
   "source": [
    "y_range = fit_fn(x_range)\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "plt.scatter(over_x, over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature transform to our data by using the function `np.polyfit()` and setting the degree to `8`. Assign the return value to variable `weights`. Then, assign the feature transform function to variable `fit_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = fit_fn(x_range)\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "plt.scatter(over_x, over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform feature transform to our data by using the function `np.polyfit()` and setting the degree to `12`. Assign the return value to variable `weights`. Then, assign the feature transform function to variable `fit_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = fit_fn(x_range)\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "plt.scatter(over_x, over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x43krsVLQaEY"
   },
   "source": [
    "Look at the last generated model (polynomial degree of 12). It definitely got a lot of data correct, but we know that this is not the sine wave function where the data actually came from and what we want to model.\n",
    "\n",
    "You may also notice that it dipped/peaked into some points that are unneccessary. It has freedom to do this as long as the data it wants to target are met.\n",
    "\n",
    "We call this overfitting, because while it will work well with this particular set of data, it might do badly with other data points. Overfitting gives us a low training error (good!), but a high test error (bad!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h74XsCVhmWTS"
   },
   "source": [
    "We're going to generate more sample (100) data points and treat them as our test data. Take note that we are taking this from our original target function `f(x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4aI0yaImWTS"
   },
   "outputs": [],
   "source": [
    "pts = 100\n",
    "test_x, test_y = generate_sample_data(pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjOQfL3imWTS"
   },
   "source": [
    "We will plot the test data as blue `+`s, and reuse the red dots for our train data. Then let us see how our model was able to capture our new data from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1649826666794,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "00YrQArmwy-1",
    "outputId": "bcf85861-cd74-427d-a051-1b8fd6f69060"
   },
   "outputs": [],
   "source": [
    "plt.scatter(over_x, over_y)\n",
    "plt.scatter(test_x, test_y, marker='+')\n",
    "\n",
    "x_range = np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01)\n",
    "y_range = fit_fn(x_range)\n",
    "plt.plot(x_range, y_range, 'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMA5TDVvwxu6"
   },
   "source": [
    "You can now see that our training data (red dots) are covered correctly, but the test data (blue +) from the same distribution as our training data are mostly missed. So, yes, this complex model captured our training data well. But since our data is also inherently noisy, this causes the model to fit the noise as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHcP9TBGmWTU"
   },
   "source": [
    "Observe what will happen if we try different values for the degree `order`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1649826666794,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "uTPu1X6amWTU",
    "outputId": "beb8da6b-2507-434c-8e5b-928a514fe346"
   },
   "outputs": [],
   "source": [
    "orders = np.arange(1, 18, 2)\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukCMXkL-QaEb"
   },
   "source": [
    "Complete the code below to display the plot of the resulting model for each order in variable `orders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 609
    },
    "executionInfo": {
     "elapsed": 1732,
     "status": "ok",
     "timestamp": 1649826668510,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "6y16ZEcEQaEc",
    "outputId": "4fc0a1f6-3cc6-4541-ab6f-6a9c1a68656c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(orders)):\n",
    "    order = orders[i]\n",
    "\n",
    "    # Write your code here\n",
    "    weight = None\n",
    "    fit_fn = None\n",
    "    \n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.scatter(over_x, over_y)\n",
    "\n",
    "    X_range = np.arange(np.min(over_x), np.max(over_x), 0.01)\n",
    "    y_range = fit_fn(X_range)\n",
    "    plt.plot(X_range, y_range, 'k')\n",
    "    plt.title('Order = ' + str(orders[i]))\n",
    "    \n",
    "    # This will get the weights of the generated model\n",
    "    weights[order] = weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HaD90e5QaEe"
   },
   "source": [
    "**Sanity Check:** You should see 9 figures in a 3x3 grid. Each grid shows the hypothesis model in increasing complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9cKMY0tmWTY"
   },
   "source": [
    "**Question #1:** Does the model with the order set to 15 have high or low bias? Does it exhibit low or high variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPibc-UBmWTZ"
   },
   "source": [
    "<!--crumb;qna;Q1-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duwomjQimWTZ"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yaAuW1YIQaEf"
   },
   "source": [
    "Print the weights of a model that is underfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1649826668511,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "FMXiLEPMmWTa",
    "outputId": "d8ee6347-7de9-423d-e836-c81fc49f2d8c"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB8w9BG6mWTb"
   },
   "source": [
    "And, print the weights of a model that is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1649826668512,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "blhDnzd2mWTc",
    "outputId": "8a9558cf-382a-435d-8dee-a84601a34b69"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I4DGVySmWTc"
   },
   "source": [
    "And, print the weights of a model that fits the data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1649826668512,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "zvMEXdNdmWTd",
    "outputId": "2b57ddfc-531a-4fc2-c4b8-d33fce8c3155"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Blj8xzKmWTd"
   },
   "source": [
    "**Question #2:** What are the notable differences in terms of the values of the weights of each of the models (aside from the number of weights)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "554JpTwKmWTe"
   },
   "source": [
    "<!--crumb;qna;Q2-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V8WtE4NmWTe"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qyClO9wmWTe"
   },
   "source": [
    "Here are the weights of each of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1649826668512,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "qt1WF_SiQaEg",
    "outputId": "ced7950b-ca77-433d-921f-0005d31e88be"
   },
   "outputs": [],
   "source": [
    "for i in orders:\n",
    "    length = weights[i].shape[0]\n",
    "    curweights = weights[i]\n",
    "    print('order =', i, end='\\t')\n",
    "    for weight in curweights:\n",
    "        print(str(weight),end='\\t')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3yf3Yp-QaEj"
   },
   "source": [
    "**Question #3:** Do we expect a low or high train loss for an unregularized model with a polynomial degree of 17?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufghkQEtmWTf"
   },
   "source": [
    "<!--crumb;qna;Q3-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byLzowr5QaEk"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tp3VeUtgmWTg"
   },
   "source": [
    "**Question #4:** Do we expect a low or high test loss for an unregularized model with a polynomial degree of 17?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkYZErOWmWTg"
   },
   "source": [
    "<!--crumb;qna;Q4-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nSf5XX_mWTg"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xZG0TkymWTg"
   },
   "source": [
    "### Checking the performance of the model\n",
    "\n",
    "We know that unregularized models can overfit with a high polynomial degree of complexity, but we have yet to see its actual performance in RMSE. \n",
    "\n",
    "Before we compute that, let us import `UnregularizedLinearRegressor` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `UnregularizedLinearRegressor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regularized_linear_regression import UnregularizedLinearRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `UnregularizedLinearRegressor` object. Set the degree to 1. Assign the object to variable `regressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `regularized_linear_regression.py` file and complete the `compute_weights()` function in the `UnregularizedLinearRegressor` class. This function computes the weights using the `np.polyfit()` function.\n",
    "\n",
    "This function has 2 parameters - `X` and `y`, where `X` is an `np.ndarray` of shape (N,) containing the training data and `y` is an `np.ndarray` of shape (N,) containing the ground truth values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `compute_weights()` function in the `UnregularizedLinearRegressor` class. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the weights by calling the function `compute_weights()` and assign the return value to variable `W`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuG-kXg6mWTi"
   },
   "source": [
    "Open `regularized_linear_regression.py` file and complete the `predict()` function in the `UnregularizedLinearRegressor` class. This function predicts values for the test data.\n",
    "\n",
    "Implement the `predict()` function in the `UnregularizedLinearRegressor` class. Inline comments should help you in completing the contents of the function.\n",
    "\n",
    "Then, make predictions on the training data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1649826668515,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "bgppllYZmWTi",
    "outputId": "b3afbed4-f2c2-498f-d6b9-ec430dc67e41"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Fiy11xImWTi"
   },
   "source": [
    "Then, check how well it performed by computing for the MSE between the predicted output vs the actual output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `compute_RMSE()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regularized_linear_regression import compute_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmXBs4MCmWTk"
   },
   "source": [
    "You may use your code for this function from the previous notebook on linear regression. Let's compute the RMSE between the predicted value and the actual value. Assign the return value to variable `train_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1649826668516,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "fNh-iEBfmWTk",
    "outputId": "d954fe5b-ff2a-4799-da49-5dfddb5615bf"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UnregularizedLinearRegressor (order=1) train error: ' + '{:.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXNp6FfxmWTk"
   },
   "source": [
    "Now, get the predictions and compute for the RMSE on our test data. Assign the return value to variable `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1649826668516,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "5KG-C6j6mWTk",
    "outputId": "f24eab2b-f315-4596-e50b-2940e9f94baa"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UnregularizedLinearRegressor (order=1) test error: ' + '{:.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's increase the degree.\n",
    "\n",
    "Instantiate a `UnregularizedLinearRegressor` object. Set the degree to 30. Assign the object to variable `regressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the training data and assign the return value to variable `y_train_predicted`. \n",
    "\n",
    "Make predictions on the test data and assign the return value to variable `y_test_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE on the train data and assign the return value to variable `train_rmse`. \n",
    "\n",
    "Compute the RMSE on the test data and assign the return value to variable `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('UnregularizedLinearRegressor (order=30) train error: ' + '{:.4f}'.format(train_rmse))\n",
    "print('UnregularizedLinearRegressor (order=30) test error: ' + '{:.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cxUPHFfomWTp"
   },
   "source": [
    "**Question #5:** Is the model above high bias or low bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMfRTIfXmWTq"
   },
   "source": [
    "<!--crumb;qna;Q5-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XeaTF4X5mWTr"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #6:** Is the model above high variance or low variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q6-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNiwATahmWTs"
   },
   "source": [
    "Visualize the `UnregularizedLinearRegressor` model. The code below is nothing new, we just visualize our `UnregularizedLinearRegressor`. It should look similar to the previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1649826668517,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "9MvICCWwmWTs",
    "outputId": "170128fa-cc5e-483d-89f2-38a88808e00f"
   },
   "outputs": [],
   "source": [
    "plt.scatter(over_x, over_y)\n",
    "plt.scatter(test_x,test_y, marker='+')\n",
    "\n",
    "x_range = np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01)\n",
    "y_range = regressor.predict(x_range)\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "\n",
    "plt.title('UnregularizedLinearRegressor (order=30) model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6liG4sUOx4b"
   },
   "source": [
    "We'll use `UnregularizedLinearRegressor` again later in the notebook.\n",
    "\n",
    "**Note:** Before we get into regularized models, you may have noticed that we are only  using the polyfit function to get our overfit models. This is because `SGDRegressor` implements a regularization by default, and there seems to be no way to switch it off. But, you could code a linear regression model algorithm from scratch to see the similar overfitting effect shown by polyfit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAWxDvcbQaEk"
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pySF-ZCeQaEk"
   },
   "source": [
    "\n",
    "It seems like overfitting producing large weights. To prevent overfitting, we will add a regularization term in our loss function that penalizes large weights. \n",
    "\n",
    "For the **analytical solution**, we use:\n",
    "\n",
    "$$(X^TX)^{-1} => (X^TX + \\lambda I)^{-1}$$ where $\\lambda$ is the regularization hyperparameter that controls how much you penalize large weights.\n",
    "\n",
    "The larger $\\lambda$ is, the higher the penalty.\n",
    "\n",
    "\n",
    "For **gradient descent**:\n",
    "\n",
    "You need to change the loss function and the weight update.\n",
    "\n",
    "\n",
    "Here, we will use `SGDRegressor`. We will also change the regularization to either L1 (LASSO) or L2 (Ridge). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTX0LVzwmWTu"
   },
   "source": [
    "We will be using matrices (and not vectors) for our train and test data in the succeeding cells.\n",
    "\n",
    "Let's convert our vectors `over_x` and `over_y` to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1649826668518,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "PnI5eA0oQaEm",
    "outputId": "ddf2c902-d643-4d02-d48a-4381b99d07c5"
   },
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(over_x, axis=1)\n",
    "y_train = np.expand_dims(over_y, axis=1)\n",
    "\n",
    "print('over_x shape', over_x.shape)\n",
    "print('over_y shape', over_y.shape)\n",
    "print('X_train shape', X_train.shape)\n",
    "print('y_train shape', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoRJbuBLQaEq"
   },
   "source": [
    "**Sanity Check:** Your results should be the same:\n",
    "```\n",
    "over_x shape (20,)\n",
    "over_y shape (20,)\n",
    "X_train shape (20, 1)\n",
    "y_train shape (20, 1)\n",
    "```\n",
    "The only difference in the shapes that you should see is the additional dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zh4ybjaBz9dl"
   },
   "source": [
    "Let's also reuse `test_x` and `test_y` as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1649826668518,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "55dv_TOj0DJt",
    "outputId": "1267b091-e2ff-424f-e821-a22aec88c739"
   },
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(test_x, axis=1)\n",
    "y_test = np.expand_dims(test_y, axis=1)\n",
    "\n",
    "print('X_test shape', X_test.shape)\n",
    "print('y_test shape', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lz1iSGiqz8Hk"
   },
   "source": [
    "Let's visualize our `X_train` and `X_test` and their correspoding `y` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1409,
     "status": "ok",
     "timestamp": 1649826669900,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "wRsc96rvzwr5",
    "outputId": "ca38c6c3-01b4-419c-c27f-5979b0367ee4"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test, y_test, marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yj4VHxN9QaEt"
   },
   "source": [
    "In the following parts, we will NOT use `np.polyfit()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `poly_feature_transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regularized_linear_regression import poly_feature_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `regularized_linear_regression.py` file and complete the `poly_feature_transform()` function. This function transforms the features to different polynomial orders.\n",
    "\n",
    "Implement the `poly_feature_transform()` function. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform `over_x` with the degree of 1 and assign the return value to variable `sample_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKMYyL1AmWTw"
   },
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1649826669901,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "CoV_Uf-GmWTw",
    "outputId": "10fdde73-82b4-4b1a-d6e0-bae54adaf102"
   },
   "outputs": [],
   "source": [
    "print(sample_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKA5anH8mWTw"
   },
   "source": [
    "__Sanity check:__ Your data should look like this:\n",
    "```\n",
    "[[-0.16595599  1.        ]\n",
    " [ 0.44064899  1.        ]\n",
    " [-0.99977125  1.        ]\n",
    " [-0.39533485  1.        ]\n",
    " [-0.70648822  1.        ]\n",
    " [-0.81532281  1.        ]\n",
    " [-0.62747958  1.        ]\n",
    " [-0.30887855  1.        ]\n",
    " [-0.20646505  1.        ]\n",
    " [ 0.07763347  1.        ]\n",
    " [-0.16161097  1.        ]\n",
    " [ 0.370439    1.        ]\n",
    " [-0.5910955   1.        ]\n",
    " [ 0.75623487  1.        ]\n",
    " [-0.94522481  1.        ]\n",
    " [ 0.34093502  1.        ]\n",
    " [-0.1653904   1.        ]\n",
    " [ 0.11737966  1.        ]\n",
    " [-0.71922612  1.        ]\n",
    " [-0.60379702  1.        ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3Bar6KnmWTy"
   },
   "source": [
    "Then, transform `over_x` with the degree of 4 and assign the return value to variable `sample_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1649826669902,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "8JXaqXO6mWTy",
    "outputId": "14240290-3593-4c4f-ec2e-573fb1d1201c"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iz80FSNtmWT0"
   },
   "source": [
    "__Sanity check:__ Your data should look like this:\n",
    "```\n",
    "[[-1.65955991e-01  2.75413908e-02 -4.57065879e-03  7.58528208e-04\n",
    "   1.00000000e+00]\n",
    " [ 4.40648987e-01  1.94171530e-01  8.55614878e-02  3.77025829e-02\n",
    "   1.00000000e+00]\n",
    " [-9.99771250e-01  9.99542553e-01 -9.99313908e-01  9.99085315e-01\n",
    "   1.00000000e+00]\n",
    " [-3.95334855e-01  1.56289647e-01 -6.17867450e-02  2.44264539e-02\n",
    "   1.00000000e+00]\n",
    " [-7.06488218e-01  4.99125603e-01 -3.52626358e-01  2.49126367e-01\n",
    "   1.00000000e+00]\n",
    " [-8.15322810e-01  6.64751285e-01 -5.41986886e-01  4.41894271e-01\n",
    "   1.00000000e+00]\n",
    " [-6.27479577e-01  3.93730620e-01 -2.47057923e-01  1.55023801e-01\n",
    "   1.00000000e+00]\n",
    " [-3.08878546e-01  9.54059561e-02 -2.94688530e-02  9.10229646e-03\n",
    "   1.00000000e+00]\n",
    " [-2.06465052e-01  4.26278175e-02 -8.80115454e-03  1.81713083e-03\n",
    "   1.00000000e+00]\n",
    " [ 7.76334680e-02  6.02695535e-03  4.67893446e-04  3.63241908e-05\n",
    "   1.00000000e+00]\n",
    " [-1.61610971e-01  2.61181060e-02 -4.22097248e-03  6.82155462e-04\n",
    "   1.00000000e+00]\n",
    " [ 3.70439001e-01  1.37225053e-01  5.08335116e-02  1.88307153e-02\n",
    "   1.00000000e+00]\n",
    " [-5.91095501e-01  3.49393891e-01 -2.06525157e-01  1.22076091e-01\n",
    "   1.00000000e+00]\n",
    " [ 7.56234873e-01  5.71891183e-01  4.32484056e-01  3.27059525e-01\n",
    "   1.00000000e+00]\n",
    " [-9.45224814e-01  8.93449948e-01 -8.44511061e-01  7.98252810e-01\n",
    "   1.00000000e+00]\n",
    " [ 3.40935020e-01  1.16236688e-01  3.96291576e-02  1.35109677e-02\n",
    "   1.00000000e+00]\n",
    " [-1.65390395e-01  2.73539828e-02 -4.52408604e-03  7.48240378e-04\n",
    "   1.00000000e+00]\n",
    " [ 1.17379657e-01  1.37779839e-02  1.61725502e-03  1.89832839e-04\n",
    "   1.00000000e+00]\n",
    " [-7.19226123e-01  5.17286216e-01 -3.72045759e-01  2.67585029e-01\n",
    "   1.00000000e+00]\n",
    " [-6.03797022e-01  3.64570844e-01 -2.20126790e-01  1.32911900e-01\n",
    "   1.00000000e+00]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYqBfGRmQaEv"
   },
   "source": [
    "Great! Now we can start training our regularized model. Our goal is to achieve good-fit models without overfitting. We will check this by visualizing the hypothesis functions.\n",
    "\n",
    "Here, we will be using sklearn's `Lasso` and `Ridge` implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxTsHJTfmWT1"
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZLRVHYvQaEx"
   },
   "source": [
    "### Lasso Regularization\n",
    "\n",
    "Import the `Lasso` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `Lasso` model with the regularization parameter set to 0.0001 and the number of iterations to 1,000,000. Assign the object to variable `lasso`.\n",
    "\n",
    "**Note**: The regularization parameter maybe named differently from what was discussed in class, so read the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YWrD8sQXmWT2"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPQWa6n6mWT3"
   },
   "source": [
    "Do not forget that to separately call the function `poly_feature_transform()` since Lasso does not incorporate feature transform unlike the function `np.poly1d()`. For now, set the polynomial order to 1. Assign the return value to variable `poly_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWBUUvWqmWT3"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKMajMrgmWT3"
   },
   "source": [
    "Then, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1649826669931,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "vnu_PKSBmWT3",
    "outputId": "eab62a61-ceb4-425f-b5b5-cd151d1a92e1"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTxpjgSqmWT4"
   },
   "source": [
    "Make predictions on the training data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1649826669931,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "D6PhngtamWT4",
    "outputId": "3e3cf4f8-ea2d-40e4-b88c-91a1f10241bf"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WyZHAX6mWT4"
   },
   "source": [
    "Compute the RMSE on the train data and assign the return value to variable `train_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 62,
     "status": "ok",
     "timestamp": 1649826669931,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "mCC20G09mWT4",
    "outputId": "333203d7-b3a1-49de-b798-2bc45f95ae42",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso (order=1) train error: ' + '{:.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nSmnE_PmWT5"
   },
   "source": [
    "And, finally, we will check if it did well on our test data as well. Make predictions on the test data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1649826669931,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "pCtEux7emWT5",
    "outputId": "f80106e1-0e10-47c0-f0e9-fb3ebcecd3a3"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReBA_XW7mWT5"
   },
   "source": [
    "Compute the RMSE on the test data and assign the return value to variable `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1649826669932,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "Bh_047DAmWT6",
    "outputId": "328e1d58-b075-41da-e170-bf7b3e1ef788"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lasso (order=1) test error: ' + '{:.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #7:**  What is the test RMSE of our model? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q7-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD82IkORmWT6"
   },
   "source": [
    "Visualize our model. Let's see how well our simple `Lasso` model fared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1649826669932,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "cFDvrwc9mWT6",
    "outputId": "f588cedc-74a4-47e3-8809-ff99e2ed67a1"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test,y_test, marker='+')\n",
    "\n",
    "x_range = np.expand_dims(np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01), axis=1)\n",
    "y_range = lasso.predict(poly_feature_transform(x_range, poly_order=1))\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "\n",
    "plt.title('Lasso (order=1) model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHR8g4wImWT8"
   },
   "source": [
    "**Question #8:** What main type of error does the model above have? Bias or variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8DVGOcGmWT8"
   },
   "source": [
    "<!--crumb;qna;Q8-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqOoP4bfmWT8"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CueaK7-XmWT9"
   },
   "source": [
    "Great! We just created a `Lasso` model with a poly degree of 1. Let's now create a `Lasso` model with a higher complexity. \n",
    "\n",
    "Instantiate a `Lasso` model with the regularization parameter set to 0.0001 and the number of iterations to 1,000,000. Assign the object to variable `lasso`. Set the polynomial order to 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the training data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE on the train data and assign the return value to variable `train_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1649826669933,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "W9TgFyXUmWT9",
    "outputId": "47ad7300-706e-414e-99c7-c44dc5cca9e2"
   },
   "outputs": [],
   "source": [
    "print('Lasso (order=30) train error: ' + '{:.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxfZDAtOmWT9"
   },
   "source": [
    "Now, compute the RMSE on the test data and assign the return value to variable `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1429,
     "status": "ok",
     "timestamp": 1649826671321,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "APriWU99mWT-",
    "outputId": "716776ac-ab31-4844-98e0-18c133c36e54"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Lasso (order=30) test error: ' + '{:.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #9:**  What is the test RMSE of our model? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q9-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9n0hVrrwmWT-"
   },
   "source": [
    "**Question #10:** Recall the train and test results of our `UnregularizedLinearRegressor` with polynomial order 30. \n",
    "Describe the train and test error of the `UnregularizedLinearRegressor` model (i.e., is the error high? is the error low?). Describe the train and test error of the `Lasso` model (i.e., is the error high? is the error low?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUz7dBX6mWT-"
   },
   "source": [
    "<!--crumb;qna;Q10-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9M2Dd5wmWT-"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXzKK93YmWT-"
   },
   "source": [
    "**Question #11:** What error did the `Lasso` model reduce? Bias or variance error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRd8krRcmWT-"
   },
   "source": [
    "<!--crumb;qna;Q11-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sLUEOBumWT-"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brrdSMZ6mWUA"
   },
   "source": [
    "Visualize our model. Let's see how well our simple `Lasso` model fared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1649826671321,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "2staf0HHmWUA",
    "outputId": "53e9e8b1-2d23-453e-8a42-c58bcbe4e66d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test,y_test, marker='+')\n",
    "\n",
    "x_range = np.expand_dims(np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01), axis=1)\n",
    "y_range = lasso.predict(poly_feature_transform(x_range, poly_order=30))\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "\n",
    "plt.title('Lasso (order=30) model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGyNwdOxmWUA"
   },
   "source": [
    "**Question #12:** Compare this with the `Lasso` order=1 model. Which of the following best describes our model: (A) overfit, (B) underfit, or (C) fits the data well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ6Q1uegmWUA"
   },
   "source": [
    "<!--crumb;qna;Q12-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVdCUHAKmWUA"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zk0JSAtmWUB"
   },
   "source": [
    "### Visualizing `Lasso` with increasing polynomial orders\n",
    "\n",
    "From our example above, we can clearly see that our regularized `Lasso` model shows improvement versus the unregularized model. Let's see its behavior across increasing polynomial orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwmyPiBBmWUB"
   },
   "outputs": [],
   "source": [
    "orders = [1, 3, 5, 7, 10, 12, 20, 30, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlcWg_wZmWUB"
   },
   "source": [
    "Instantiate a `Lasso` model with the regularization parameter set to 0.0001 and the number of iterations to 1,000,000. Assign the object to variable `lasso`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njAi264lmWUB"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApdAbC16mWUC"
   },
   "source": [
    "To make the following code work, you have to do the following per iteration:\n",
    "1. Perform polynomial feature transform on the training data according to the current polynomial order\n",
    "1. Train the model to your transformed train data and the training labels\n",
    "1. Perform polynomial feature transform `x_range` according to the current polynomial order\n",
    "1. Make the model run predictions on your transformed `x_range`\n",
    "1. Collect the weights per model (this is not really needed for the visuals, but we want to see the weights later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "executionInfo": {
     "elapsed": 934,
     "status": "ok",
     "timestamp": 1649826672250,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "lBZnNVLFmWUC",
    "outputId": "fac9169e-72f6-490a-d95e-d3e833a60bf3"
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i in range(len(orders)):\n",
    "    order = orders[i]\n",
    "        \n",
    "    # Write your code here\n",
    "    poly_x = None\n",
    "    \n",
    "    # Plotting the hypothesis function\n",
    "    # Plotting the predictions for a range of x (this draws our hypothesis function)\n",
    "    X_range = np.expand_dims(np.arange(-0.9, 0.9, 0.02), 1)\n",
    "    \n",
    "    # Write your code here\n",
    "    X_range_poly = None\n",
    "    y_range_predicted = None\n",
    "    \n",
    "    # This just plots the i + 1 figure in the 3x3 figure grid\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Plotting the training data\n",
    "    plt.scatter(X_train, y_train)\n",
    "    # Plotting the hypothesis function\n",
    "    plt.plot(X_range, y_range_predicted, 'b')\n",
    "    \n",
    "    # Plotting the optimal answer\n",
    "    x_range_optimal = np.arange(np.min(X_train), np.max(X_train), 0.01)\n",
    "    y_range_optimal = np.sin(6 * x_range_optimal)\n",
    "    plt.plot(x_range_optimal, y_range_optimal, 'k:')\n",
    "    \n",
    "    # Change the limit, and order \"titles\"\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title('Lasso, Order=' + str(order))\n",
    "    \n",
    "    # Write your code here\n",
    "    weights[order] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFFSKfKEQaE1"
   },
   "source": [
    "### Checking the Lasso weights\n",
    "Let's see the effect on the `Lasso` (L1) regularization on the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1649826673163,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "YIf-MunhQaE1",
    "outputId": "53f7a1ff-b0eb-437c-f67a-0bd026cb1564",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in orders:\n",
    "    length = weights[i].shape[0]\n",
    "    bound = np.min([length, 10])\n",
    "    curweights = weights[i][:bound]\n",
    "    print('order =', i, end='\\t')\n",
    "    for weight in curweights:\n",
    "        print(str(weight),end='\\t')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_j9HQ_bYQaE3"
   },
   "source": [
    "**Sanity Check:** You should not see the weights straying away from 0 like they did before applying regularization. You will also see some weights turn into 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HpX4zKzmWUS"
   },
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regularization\n",
    "\n",
    "Import the `Ridge` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdAnB8x2mWUT"
   },
   "source": [
    "Instantiate a `Ridge` model with the regularization parameter set to 0.0001 and the solver to `auto`. Assign the object to variable `ridge`.\n",
    "\n",
    "**Note**: The regularization parameter maybe named differently from what was discussed in class, so read the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlURnZudmWUU"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget that to separately call the function `poly_feature_transform()` since Ridge does not incorporate feature transform unlike the function `np.poly1d()`. For now, set the polynomial order to 1. Assign the return value to variable `poly_x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uy34X89YmWUU"
   },
   "source": [
    "Then, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1649826673176,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "UtaQBpGomWUU",
    "outputId": "d2dd4eca-dfdd-4746-8ad3-6d16a84e23f4",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the training data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE on the train data and assign the return value to variable `train_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ridge (order=1) train error: ' + '{:.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, finally, we will check if it did well on our test data as well. Make predictions on the test data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE on the test data and assign the return value to variable `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Ridge (order=1) test error: ' + '{:.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #13:**  What is the test RMSE of our model? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q13-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA7aqHU-mWUd"
   },
   "source": [
    "Visualize our model. Let's see how well our simple `Ridge` model fared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1649826673177,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "Ack4-yJ5mWUd",
    "outputId": "aaa01d93-e5f7-4979-a962-f5310394a79d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test,y_test, marker='+')\n",
    "\n",
    "x_range = np.expand_dims(np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01), axis=1)\n",
    "y_range = ridge.predict(poly_feature_transform(x_range, poly_order=1))\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "\n",
    "plt.title('Ridge (order=1) model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQgHceDpmWUg"
   },
   "source": [
    "Just like in `Lasso`, we will also create a `Ridge` model with a higher complexity, where polynomial order is set to 30. \n",
    "\n",
    "Instantiate a `Ridge` model with the regularization parameter set to 0.0001 and the solver to `auto`. Assign the object to variable `ridge`. Set the polynomial order to 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions on the training data and assign the return value to variable `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the RMSE on the train data and assign the return value to variable `train_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge (order=30) train error: \" + '{:.4f}'.format(train_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hjNf00xmWUg"
   },
   "source": [
    "Now, compute the RMSE on the test data and assign the return value to variable `test_rmse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1649826673178,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "Hm4mVd0DmWUh",
    "outputId": "eb388d96-1da4-4ffa-e6fd-7542b8dd4000"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ridge (order=30) test error: ' + '{:.4f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #14:**  What is the test RMSE of our model? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q14-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVt5wL5OmWUi"
   },
   "source": [
    "Visualize our model. Let's see how well our `Ridge` (order=30) model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1649826673178,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "lo5ulA-KmWUi",
    "outputId": "6d7589f5-d505-49b4-d563-d35e6b4ba96d"
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_test,y_test, marker='+')\n",
    "\n",
    "x_range = np.expand_dims(np.arange(np.min(over_x), np.max(over_x) + 0.01, 0.01), axis=1)\n",
    "y_range = ridge.predict(poly_feature_transform(x_range, poly_order=30))\n",
    "plt.plot(x_range, y_range, 'k')\n",
    "\n",
    "plt.title('Ridge (order=1) model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9MR8kGPmWUj"
   },
   "source": [
    "**Question #15:** What error did the `Ridge` model reduce? Bias or variance error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwuXRMrZmWUj"
   },
   "source": [
    "<!--crumb;qna;Q15-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CuFXDWYmWUj"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9jDvncFmWUk"
   },
   "source": [
    "**Question #16:** Between the `UnregularizedLinearRegressor` and the regularized models, which achieved a lower train error? Why does this behavior happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XE8KLpfmWUk"
   },
   "source": [
    "<!--crumb;qna;Q16-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYdFQcR6mWUl"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0uLZAc9mWUl"
   },
   "source": [
    "**Question #17:** Between the `UnregularizedLinearRegressor` and the regularized models, which achieved a lower test error? Why does this behavior happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyHzFPe0mWUm"
   },
   "source": [
    "<!--crumb;qna;Q17-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQJRQSpFmWUm"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEt9GYC5mWUn"
   },
   "source": [
    "### Visualizing `Ridge` with increasing polynomial orders\n",
    "\n",
    "From our example above, we can clearly see that our regularized `Ridge` model did not overfit the data unlike `UnregularizedLinearRegressor`. Let's also see its behavior across increasing polynomial orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uzU-K-hmWUn"
   },
   "outputs": [],
   "source": [
    "orders = [1, 3, 5, 7, 10, 12, 20, 30, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEJuNG4ImWUo"
   },
   "source": [
    "Instantiate a `Ridge` model with the regularization parameter set to 0.0001 and the solver to `auto`. Assign the object to variable `ridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "847mQE4PmWUo"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJrJHAKEmWUo"
   },
   "source": [
    "To make the following code work, you have to do the following per iteration:\n",
    "1. Perform polynomial feature transform on the training data according to the current polynomial order\n",
    "1. Train the model to your transformed train data and the training labels\n",
    "1. Perform polynomial feature transform `x_range` according to the current polynomial order\n",
    "1. Make the model run predictions on your transformed `x_range`\n",
    "1. Collect the weights per model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "executionInfo": {
     "elapsed": 1779,
     "status": "ok",
     "timestamp": 1649826674934,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "Pz8xDtw_mWUo",
    "outputId": "c4b8ded3-c602-4fd7-e04c-c5b962afb150"
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i in range(len(orders)):\n",
    "    order = orders[i]\n",
    "        \n",
    "    # Write your code here\n",
    "    poly_x = None\n",
    "    \n",
    "    # Plotting the hypothesis function\n",
    "    # Plotting the predictions for a range of x (this draws our hypothesis function)\n",
    "    X_range = np.expand_dims(np.arange(-0.9, 0.9, 0.02), 1)\n",
    "    \n",
    "    # Write your code here\n",
    "    X_range_poly = None\n",
    "    y_range_predicted = None\n",
    "    \n",
    "    # This just plots the i+1 figure in the 3x3 figure grid\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Plotting the training data\n",
    "    plt.scatter(X_train, y_train)\n",
    "    # Plotting the hypothesis function\n",
    "    plt.plot(X_range, y_range_predicted, 'b')\n",
    "    \n",
    "    # Plotting the optimal answer\n",
    "    x_range_optimal = np.arange(np.min(X_train), np.max(X_train), 0.01)\n",
    "    y_range_optimal = np.sin(6 * x_range_optimal)\n",
    "    plt.plot(x_range_optimal, y_range_optimal, 'k:')\n",
    "    \n",
    "    # Change the limit, and order \"titles\"\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title('Ridge, Order=' + str(order))\n",
    "    \n",
    "    # Write your code here\n",
    "    weights[order] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzOJGx9MQaE-"
   },
   "source": [
    "### Checking the Ridge weights\n",
    "Let's see the effect on the `Ridge` (L2) regularization on the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1649826674936,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "uUKo4-PRQaE_",
    "outputId": "d204f766-9679-45c2-e26d-44a14bf76c5c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in orders:\n",
    "    length = weights[i].shape[0]\n",
    "    bound = np.min([length, 10])\n",
    "    curweights = weights[i][:bound]\n",
    "    print('order =', i, end='\\t')\n",
    "    for weight in curweights:\n",
    "        print(str(weight),end='\\t')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GvWOH23hmWUq"
   },
   "source": [
    "__Sanity Check:__ You should see the weights being closer to 0 compared to the `UnregularizedLinearRegressor`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOxufTZQmWUs"
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftscaqXzmWUs"
   },
   "source": [
    "### Effect of the regularization parameter\n",
    "\n",
    "Let's try to adjust the regularization parameter and check its effect on the model. \n",
    "\n",
    "We'll just reuse our `Ridge` model from the previous cells, but we will change the regularization parameter to `40`.\n",
    "\n",
    "Instantiate a `Ridge` model with the regularization parameter set to 40 and the solver to `auto`. Assign the object to variable `ridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFYDjod4mWUs"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "executionInfo": {
     "elapsed": 2896,
     "status": "ok",
     "timestamp": 1649826677822,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "FcdrPra5mWUs",
    "outputId": "21d58d9b-c65f-4c11-8e6a-f02f93ea9edd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i in range(len(orders)):\n",
    "    order = orders[i]\n",
    "        \n",
    "    # Write your code here\n",
    "    poly_x = None\n",
    "    \n",
    "    # Plotting the hypothesis function\n",
    "    # Plotting the predictions for a range of x (this draws our hypothesis function)\n",
    "    X_range = np.expand_dims(np.arange(-0.9, 0.9, 0.02), 1)\n",
    "    \n",
    "    # Write your code here\n",
    "    X_range_poly = None\n",
    "    y_range_predicted = None\n",
    "    \n",
    "    # This just plots the i+1 figure in the 3x3 figure grid\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Plotting the training data\n",
    "    plt.scatter(X_train, y_train)\n",
    "    # Plotting the hypothesis function\n",
    "    plt.plot(X_range, y_range_predicted, 'b')\n",
    "    \n",
    "    # Plotting the optimal answer\n",
    "    x_range_optimal = np.arange(np.min(X_train), np.max(X_train), 0.01)\n",
    "    y_range_optimal = np.sin(6 * x_range_optimal)\n",
    "    plt.plot(x_range_optimal, y_range_optimal, 'k:')\n",
    "    \n",
    "    # Change the limit, and order \"titles\"\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title('Ridge, Order=' + str(order) + ', $\\lambda$ = 40')\n",
    "    \n",
    "    # Write your code here\n",
    "    weights[order] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAJe_QFhmWUs"
   },
   "source": [
    "**Question #18:** What happened to the models when we set the regularization parameter to 40 (compared to the original `Ridge` model)? Why are we seeing this behavior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8n8h3RsmWUt"
   },
   "source": [
    "<!--crumb;qna;Q18-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrEe5oafmWUt"
   },
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGCPGmJzmWUt"
   },
   "source": [
    "Then, let's do the opposite. \n",
    "\n",
    "Instantiate a `Ridge` model with the regularization parameter set to 0 and the solver to `auto`. Assign the object to variable `ridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z2HFNG8ImWUt"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "executionInfo": {
     "elapsed": 3500,
     "status": "ok",
     "timestamp": 1649826681705,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "UidQlIckmWUu",
    "outputId": "5601e753-ad8a-4b3e-acbc-d267aef10794"
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i in range(len(orders)):\n",
    "    order = orders[i]\n",
    "        \n",
    "    # Write your code here\n",
    "    poly_x = None\n",
    "    \n",
    "    # Plotting the hypothesis function\n",
    "    # Plotting the predictions for a range of x (this draws our hypothesis function)\n",
    "    X_range = np.expand_dims(np.arange(-0.9, 0.9, 0.02), 1)\n",
    "    \n",
    "    # Write your code here\n",
    "    X_range_poly = None\n",
    "    y_range_pred = None\n",
    "    \n",
    "    # This just plots the i+1 figure in the 3x3 figure grid\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    \n",
    "    # Plotting the training data\n",
    "    plt.scatter(X_train, y_train)\n",
    "    # Plotting the hypothesis function\n",
    "    plt.plot(X_range,y_range_pred, 'b')\n",
    "    \n",
    "    # Plotting the optimal answer\n",
    "    x_range_optimal = np.arange(np.min(X_train), np.max(X_train), 0.01)\n",
    "    y_range_optimal = np.sin(6 * x_range_optimal)\n",
    "    plt.plot(x_range_optimal, y_range_optimal, 'k:')\n",
    "    \n",
    "    # Change the limit, and order \"titles\"\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.title('Ridge, Order=' + str(order) + ', $\\lambda$ = 0')\n",
    "    \n",
    "    # Write your code here\n",
    "    weights[order] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiwLNtp6QaFA"
   },
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "yD7LUFo9QaFB"
   },
   "source": [
    "## Another way of preventing overfit models\n",
    "\n",
    "In class, we discussed that having more data points will prevent overfitting. Let's see what hypothesis function we'll end up with if we have more than 20 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1649826682565,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "0DKchvHsQaFE",
    "outputId": "f918960d-2644-455e-8d32-ccae4f7fa510"
   },
   "outputs": [],
   "source": [
    "pts = 1000\n",
    "\n",
    "# Write your code here\n",
    "over_x, over_y = None\n",
    "\n",
    "plt.scatter(over_x,over_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUsvPemOmWUx"
   },
   "source": [
    "We will create an `UnregularizedLinearRegressor` and apply it with different polynomial orders again but now with more training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2rBGmprmWUy"
   },
   "outputs": [],
   "source": [
    "orders = np.arange(1, 40, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opcyMG7qmWUy"
   },
   "source": [
    "To make the following code work, you have to do the following per iteration:\n",
    "1. Create an `UnregularizedLinearRegressor` with the polynomial degree matching the current iteration's order\n",
    "1. Fit the model to our new data\n",
    "1. Make the model run predictions on our new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "executionInfo": {
     "elapsed": 12932,
     "status": "ok",
     "timestamp": 1649826695485,
     "user": {
      "displayName": "Courtney Ngo",
      "userId": "01361140591205022195"
     },
     "user_tz": -480
    },
    "id": "HPMwds5qmWU3",
    "outputId": "ea8c4c42-24e6-4a2a-bd25-d56655fe07bf"
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(len(orders)):\n",
    "    order = orders[i]\n",
    "\n",
    "    # Write your code here\n",
    "    regressor = None\n",
    "    \n",
    "    plt.subplot(5, 4, i + 1)\n",
    "    plt.scatter(over_x, over_y)\n",
    "\n",
    "    X_range = np.arange(np.min(over_x), np.max(over_x), 0.01)\n",
    "    \n",
    "    # Write your code here\n",
    "    y_range_predicted = None\n",
    "    \n",
    "    plt.plot(X_range, y_range_predicted, 'k')\n",
    "    plt.title('Order = ' + str(orders[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "-puKqC5AQaFH"
   },
   "source": [
    "As you can see, even without regularization, the more data we have, our model is more consistent and less likely to overfit. This suggests that overfitting is relative to the **complexity** of the hypothesis function as well as the **number of data points** in your training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeJbyV_xQaFI"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpXk89GUQaFJ"
   },
   "source": [
    "Congratulations!\n",
    "\n",
    "You have now created a linear regression model that can fit a complex function without running into the problem of overfitting. \n",
    "\n",
    "<img src=\"http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png\">\n",
    "In the figure above, we want to be where the error is the lowest\n",
    "\n",
    "To **summarize**:\n",
    "* We definitely do not want to underfit, so we allow feature transform to properly capture data\n",
    "* But we don't want to overfit either by doing feature transform, so we must make sure that we don't overfit by keeping an eye on the weights.\n",
    "* We do this by updating our loss function to also consider large weights (weights far from zero) as additional loss\n",
    "* Weights now update to make sure that training error is minimal and weights be as close to 0 as possible.\n",
    "\n",
    "\n",
    "\n",
    "Next, we will move on to logistic regression, which builds on top of linear regression. Unlike linear regression, logistic regression is a classification technique.\n",
    "\n",
    "See you in the next notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zc_943wGQaFL"
   },
   "source": [
    "### <center>fin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1627309466899,
     "user": {
      "displayName": "Courtney Anne Ngo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiIfyt6AkF7HZbA8Hocq9kscgqdvyk-Dih_JRBcRg=s64",
      "userId": "12529055089461389747"
     },
     "user_tz": -480
    },
    "id": "MkZqPEWhQaFM"
   },
   "source": [
    "\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->\n",
    "\n",
    "<sup>made/compiled by daniel stanley tan & courtney anne ngo 🐰 & thomas james tiam-lee</sup> <br>\n",
    "<sup>for comments, corrections, suggestions, please email:</sup>\n",
    "<sup> danieltan07@gmail.com & courtneyngo@gmail.com & thomasjamestiamlee@gmail.com</sup><br>\n",
    "<sup>please cc your instructor, too</sup>\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02 - regularized linear regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
