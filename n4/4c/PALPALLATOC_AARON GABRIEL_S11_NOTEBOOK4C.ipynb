{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Name/Section:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Logistic Regression Exercise\n",
    "\n",
    "In this notebook, we will extend our `SGDClassifier` to train a multinomial dataset.\n",
    "\n",
    "You will see that there is little difference between in generating a binomial logistic regression model from a multinomial logistic regression model in `scikit`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with 'A: ' on them. The answer must strictly consume one line only.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* There are commented markdown cells that have crumbs. Do not delete them or separate them from the cell originally directly below it. \n",
    "* You may add new cells for \"scrap work\" as long as the crumbs are not separated from the cell below it.\n",
    "* The notebooks will undergo a 'Restart and Run All' command, so make sure that your code is working properly.\n",
    "* You are expected to understand the data set loading and processing separately from this class.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import **matplotlib**, **csv**, and **numpy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset\n",
    "\n",
    "Let's use the `make_blobs()` function to create a dataset with 1650 instances centered in (-5, 0), (0, 0), and (-1, -4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "centers = [[-5, 0], [0, 0], [-1, -4]]\n",
    "\n",
    "X, y = make_blobs(n_samples=1650, \n",
    "                  centers=centers, \n",
    "                  random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the number of instances per class. Below are our classes and their corresponding colors in the graph later.\n",
    "- class `0`, violet\n",
    "- class `1`, turquoise\n",
    "- class `2`, yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "X_2 = X[y == 2]\n",
    "\n",
    "print('Number of class 0:', len(X_0))\n",
    "print('Number of class 1:', len(X_1))\n",
    "print('Number of class 2:', len(X_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 550 instances for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the dataset into train and test set. The test set will contain 50 instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Select 50 `class 0` instances\n",
    "selected_0 = np.random.choice(np.arange(len(X_0)),\n",
    "                              size=50,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 50 `class 1` instances\n",
    "selected_1 = np.random.choice(np.arange(len(X_1)),\n",
    "                              size=50,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 50 `class 2` instances\n",
    "selected_2 = np.random.choice(np.arange(len(X_2)),\n",
    "                              size=50,\n",
    "                              replace=False)\n",
    "\n",
    "# Form the test set\n",
    "X_test = np.concatenate((X_0[selected_0],\n",
    "                         X_1[selected_1],\n",
    "                         X_2[selected_2]))\n",
    "y_test = np.concatenate((np.array([0 for _ in range(50)]),\n",
    "                         np.array([1 for _ in range(50)]),\n",
    "                         np.array([2 for _ in range(50)])))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining 1500 instances will be a part of the train set, where each class has 500 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((np.delete(X_0, selected_0, 0),\n",
    "                          np.delete(X_1, selected_1, 0),\n",
    "                          np.delete(X_2, selected_2, 0)))\n",
    "y_train = np.concatenate((np.array([0 for _ in range(500)]),\n",
    "                          np.array([1 for _ in range(500)]),\n",
    "                          np.array([2 for _ in range(500)])))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
    "plt.title('Train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
    "plt.title('Test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** You should have a similar graph like our training data, but now with fewer points. The colors should appear in the same area, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data which we will feed into our multinomial logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression\n",
    "\n",
    "Use `sklearn`'s `SGDClassifier` to create a logistic regression model. Since we have three classes (`Class 0`, `Class 1`, and `Class 2`), we will be implementing a multinomial logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `SGDClassifier` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an `SGDClassifier` object. Set the following hyperparameters:\n",
    "- Loss function: 'log_loss'\n",
    "- Initial learning rate: 0.0001\n",
    "- Learning rate: 'constant'\n",
    "- Random state: 1\n",
    "- Verbose: 0\n",
    "\n",
    "See the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the maximum number of epochs to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `DataLoader` class to train via mini-batch gradient descent\n",
    "\n",
    "We will train the model using mini-batch gradient descent. \n",
    "\n",
    "Use the `data_loader.py` file that we implemented in the previous notebook. Import the `DataLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an `DataLoader` object. Pass the `X` and `y` of the train set and `20` as our `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "e = 0\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "labels = np.unique(y_train)\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # TODO: Get the batch for this epoch.\n",
    "    X_batch, y_batch = None\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        \n",
    "        # TODO: Partial fit the model to the subset you selected\n",
    "        # In partial fit, you have to pass a classes parameters, use labels as the value\n",
    "        \n",
    "        \n",
    "        # Compute the loss\n",
    "        y_pred = model.predict_proba(X_train)\n",
    "        loss += log_loss(y_train, y_pred)\n",
    "        \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss:', (loss / len(X_batch)))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.05:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #1:** How many epochs did the model train before convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q1-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #2:** What is the average loss at the last epoch? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q2-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our trained model on the test data\n",
    "\n",
    "Now, let's get the prediction results on the test data to see if our model can handle unseen instances. Store the predicted labels in the variable `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the ground truth labels with the predicted labels. Store the total number of correct predictions in the variable `num_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for the accuracy. Store the accuracy in the variable `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #3:** What is the accuracy of the model when evaluated on the test set? Express your answer in a floating point number from 0 to 1. Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q3-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the probabilities of each instance in the test set belonging to all of the 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "\n",
    "\n",
    "print('Sum of the probabilities of each instance: \\n', np.sum(probabilities, axis=1))\n",
    "print('Probabilities:\\n', probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The sum probability of each instance should all be equal to one (you should see a vector of length 100 all containing 1s). The probabilities should be a (100, 3) matrix. Each row signifies a test instance and the columns represent the probability of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, in the binomial logistic regression, your weights will have a shape of `(1, num_features)`, where `num_features` is the number of features in the dataset.\n",
    "\n",
    "In this multinomial logistic regression problem, your weights/coefficients have a `(3, num_features)` shape, where `num_features` in this particular example is 2. You can confirm this by checking the shape of the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #4:** What does it mean to have a 3 rows of weights in multinomial logistic regression? Why is it different from the binomial logistic regression weight shape?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q4-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing our model prediction boundaries\n",
    "\n",
    "To see the prediction boundary, we will predict each possible point on our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_min, x_max = X_train[:,0].min() - 1, X_train[:,0].max() + 1\n",
    "y_min, y_max = X_train[:,1].min() - 1, X_train[:,1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "\n",
    "\n",
    "x_test = np.squeeze(np.stack((xx.ravel(),yy.ravel()))).T\n",
    "Z = model.predict(x_test)\n",
    "\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #5:** Some of the instances of other classes are found in the regions of other classes. For example, some cyan dots are found in the violet and yellow regions. Does this indicate that our model is not trained correctly? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q5-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset\n",
    "We will use the Iris dataset as our dataset. Each instance represents an Iris flower using 4 distinct features:\n",
    "- `sepal_length` - length of the sepal in centimeters\n",
    "- `sepal_width` - width of the sepal in centimeters\n",
    "- `petal_length` - length of the petal in centimeters\n",
    "- `petal_width` - width of the petal in centimeters\n",
    "\n",
    "Iris flowers can be 3 divided into different classes, which are:\n",
    "- `Iris-setosa` - class `0`\n",
    "- `Iris-versicolor` - class `1`\n",
    "- `Iris-virginica` - class `2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load `Iris.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    'Iris-setosa': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-virginica': 2\n",
    "}\n",
    "\n",
    "with open('Iris.csv', 'r') as csv_file:\n",
    "    raw_data = csv.reader(csv_file)\n",
    "    X_iris = np.empty((0, 4), float)\n",
    "    y_iris = np.empty((0, 1), int)\n",
    "    for row in raw_data:\n",
    "        X_iris = np.vstack([X_iris, np.array([float(row[0]),     # column for sepal_length\n",
    "                                              float(row[1]),     # column for sepal_width\n",
    "                                              float(row[2]),     # column for petal_length\n",
    "                                              float(row[3])])])  # column for petal_width\n",
    "        \n",
    "        y_iris = np.append(y_iris, np.array([classes[row[4]]]))  # column for class\n",
    "\n",
    "# This transforms the vector of length N into a matrix with shape (N, 1)\n",
    "y_house = np.expand_dims(y_iris, 1) \n",
    "\n",
    "print('Training data shape:', X_iris.shape)\n",
    "print('Ground truth values shape:', y_iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #6:** How many instances do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q6-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the number of instances per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris_0 = X_iris[y_iris == 0]\n",
    "X_iris_1 = X_iris[y_iris == 1]\n",
    "X_iris_2 = X_iris[y_iris == 2]\n",
    "\n",
    "print('Number of class 0:', len(X_iris_0))\n",
    "print('Number of class 1:', len(X_iris_1))\n",
    "print('Number of class 2:', len(X_iris_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50 instances for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the dataset into train and test set. The test set will contain 10 instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Select 10 `class 0` instances\n",
    "selected_0 = np.random.choice(np.arange(len(X_iris_0)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 1` instances\n",
    "selected_1 = np.random.choice(np.arange(len(X_iris_1)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_2 = np.random.choice(np.arange(len(X_iris_2)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Form the test set\n",
    "X_test = np.concatenate((X_iris_0[selected_0],\n",
    "                         X_iris_1[selected_1],\n",
    "                         X_iris_2[selected_2]))\n",
    "y_test = np.concatenate((np.array([0 for _ in range(10)]),\n",
    "                         np.array([1 for _ in range(10)]),\n",
    "                         np.array([2 for _ in range(10)])))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining 120 instances will be a part of the train set, where each class has 40 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((np.delete(X_iris_0, selected_0, 0),\n",
    "                          np.delete(X_iris_1, selected_1, 0),\n",
    "                          np.delete(X_iris_2, selected_2, 0)))\n",
    "y_train = np.concatenate((np.array([0 for _ in range(40)]),\n",
    "                          np.array([1 for _ in range(40)]),\n",
    "                          np.array([2 for _ in range(40)])))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression\n",
    "\n",
    "Use `sklearn`'s `SGDClassifier` to create a logistic regression model. Since we have three classes (`Iris-setosa`, `Iris-versicolor`, and `Iris-virginica`), we will be implementing a multinomial logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an `SGDClassifier` object. Set the following hyperparameters:\n",
    "- Loss function: 'log_loss'\n",
    "- Initial learning rate: 0.01\n",
    "- Learning rate: 'constant'\n",
    "- Random state: 1\n",
    "- Verbose: 0\n",
    "\n",
    "See the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the maximum number of epochs to 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the `DataLoader` class to train via mini-batch gradient descent\n",
    "\n",
    "We will train the model using mini-batch gradient descent. \n",
    "\n",
    "Instantiate a `DataLoader` object. Pass the `X` and `y` of the train set and `5` as our `batch_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "labels = np.unique(y_iris)\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # TODO: Get the batch for this epoch.\n",
    "    X_batch, y_batch = None\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        \n",
    "        # TODO: Partial fit the model to the subset you selected\n",
    "        # In partial fit, you have to pass a classes parameters, use labels as the value\n",
    "        \n",
    "        \n",
    "        # Compute the loss\n",
    "        y_pred = model.predict_proba(X_train)\n",
    "        loss += log_loss(y_train, y_pred)\n",
    "        \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss:', (loss / len(X_batch)))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.05:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #7:** How many epochs did the model train before convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q7-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #8:** What is the average loss at the last epoch? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q8-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our trained model on the test data\n",
    "\n",
    "Now, let's get the prediction results on the test data to see if our model can handle unseen instances. Store the predicted labels in the variable `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the ground truth labels with the predicted labels. Store the total number of correct predictions in the variable `num_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for the accuracy. Store the accuracy in the variable `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #9:** What is the accuracy of the model when evaluated on the test set? Express your answer in a floating point number from 0 to 1. Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q9-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model with your own input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "print('Enter the sepal_length:')\n",
    "f1 = float(input())\n",
    "\n",
    "print('Enter the sepal_width:')\n",
    "f2 = float(input())\n",
    "\n",
    "print('Enter the petal_length:')\n",
    "f3 = float(input())\n",
    "\n",
    "print('Enter the petal_width:')\n",
    "f4 = float(input())\n",
    "\n",
    "pred = np.squeeze(model.predict([[f1, f2, f3, f4]]))\n",
    "\n",
    "print('The class is', classes[pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Congratulations, you made it this far! We've been able to generate data, classify them using our logistic regression model, and see how it performs.\n",
    "\n",
    "Go ahead and try placing the centers nearer each other to see if our model can still handle more complex data, just remember to place them back before submission.\n",
    "\n",
    "Now, we have a machine learning algorithm that can classify an instance into multiple classes. We also have the probability of an instance belonging to each of the class. This allows us to put a threshold on the probability (e.g. if the highest probability on an instance is 35%, we can say 'we are not sure' instead of giving a prediction; but if the highest probability is 90%, we can confidently claim our prediction)\n",
    "\n",
    "It is important that you know and understand logistic regression because these will be the building blocks of our next topic: neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <center>fin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- DO NOT MODIFY OR DELETE THIS -->\n",
    "<sup>made/compiled by daniel stanley tan & courtney anne ngo 🐰 & thomas james tiam-lee</sup> <br>\n",
    "<sup>for comments, corrections, suggestions, please email:</sup><sup> danieltan07@gmail.com & courtneyngo@gmail.com & thomasjamestiamlee@gmail.com</sup><br>\n",
    "<sup>please cc your instructor, too</sup>\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
