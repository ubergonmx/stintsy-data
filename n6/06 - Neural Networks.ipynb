{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Name/Section:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: Aaron Palpallatoc / S11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Exercise\n",
    "\n",
    "In this notebook, we will extend our `SGDClassifier` into a 2-layer neural network to train on a multinomial dataset.\n",
    "\n",
    "**Note: there is a jump from how scikit and PyTorch train their models.** It might be helpful to think that PyTorch sets the design of the computation graph first, then starts a session to \"feed\" the data for training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with 'A: ' on them. The answer must strictly consume one line only.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* There are commented markdown cells that have crumbs. Do not delete them or separate them from the cell originally directly below it. \n",
    "* You may add new cells for \"scrap work\" as long as the crumbs are not separated from the cell below it.\n",
    "* The notebooks will undergo a 'Restart and Run All' command, so make sure that your code is working properly.\n",
    "* You are expected to understand the data set loading and processing separately from this class.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import **matplotlib**, **csv**, **numpy**, and **torch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Dataset\n",
    "\n",
    "Let's use the `make_blobs()` function to create a dataset with 1650 instances centered in (-6, 0), (0, 0), and (-3, -5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "centers = [[-6, 0], [0, 0], [-3, -5]]\n",
    "\n",
    "X, y = make_blobs(n_samples=1650, \n",
    "                  centers=centers, \n",
    "                  random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the number of instances per class. Below are our classes and their corresponding colors in the graph later.\n",
    "- class `0`, violet\n",
    "- class `1`, turquoise\n",
    "- class `2`, yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = X[y == 0]\n",
    "X_1 = X[y == 1]\n",
    "X_2 = X[y == 2]\n",
    "\n",
    "print('Number of class 0:', len(X_0))\n",
    "print('Number of class 1:', len(X_1))\n",
    "print('Number of class 2:', len(X_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 550 instances for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the dataset into train and test set. The test set will contain 50 instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# Select 50 `class 0` instances\n",
    "selected_0 = np.random.choice(np.arange(len(X_0)),\n",
    "                              size=50,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 50 `class 1` instances\n",
    "selected_1 = np.random.choice(np.arange(len(X_1)),\n",
    "                              size=50,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 50 `class 2` instances\n",
    "selected_2 = np.random.choice(np.arange(len(X_2)),\n",
    "                              size=50,\n",
    "                              replace=False)\n",
    "\n",
    "# Form the test set\n",
    "X_test = np.concatenate((X_0[selected_0],\n",
    "                         X_1[selected_1],\n",
    "                         X_2[selected_2]))\n",
    "y_test = np.concatenate((np.array([0 for _ in range(50)]),\n",
    "                         np.array([1 for _ in range(50)]),\n",
    "                         np.array([2 for _ in range(50)])))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining 1500 instances will be a part of the train set, where each class has 500 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((np.delete(X_0, selected_0, 0),\n",
    "                          np.delete(X_1, selected_1, 0),\n",
    "                          np.delete(X_2, selected_2, 0)))\n",
    "y_train = np.concatenate((np.array([0 for _ in range(500)]),\n",
    "                          np.array([1 for _ in range(500)]),\n",
    "                          np.array([2 for _ in range(500)])))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train)\n",
    "plt.title('Train data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
    "plt.title('Test data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** You should have a similar graph like our training data, but now with fewer points. The colors should appear in the same area, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `np.ndarray` arrays to `torch.Tensor`. We use `torch.Tensor` in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `X_train` to the datatype `torch.Tensor` and assign the return value to variable `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `y_train` to the datatype `torch.Tensor` and assign the return value to variable `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `X_test` to the datatype `torch.Tensor` and assign the return value to variable `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `y_test` to the datatype `torch.Tensor` and assign the return value to variable `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the data which we will feed into our neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n",
    "\n",
    "We will follow the pseudocode below:\n",
    "\n",
    "\n",
    "1. Set up the size of our network.\n",
    "2. Initialize weights variables.\n",
    "\n",
    "start loop\n",
    "3. Do forward propagation.\n",
    "4. Get the predictions.\n",
    "5. Calculate for the loss.\n",
    "6. Do backward propagation to update/optimize the weight variables.\n",
    "\n",
    "end loop\n",
    "\n",
    "Open `neural_network.py` file. Some of the functions in the `NeuralNetwork` class are not yet implemented. We will implement the missing parts of this class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `NeuralNetwork` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Setting up the size of the network\n",
    "\n",
    "Instantiate a `NeuralNetwork` object. Set the following parameters:\n",
    "- `list_hidden` = (5, 10)\n",
    "- `activation` = `sigmoid`\n",
    "\n",
    "Here, we are creating a Neural Network with two hidden layers, where there are 5 units in the first layer and 10 units in the second layer.\n",
    "\n",
    "Set the other parameters according to the synthetic dataset that we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open `neural_network.py` file and complete the `create_network()` function in the `NeuralNetwork` class. This function creates the layers of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `create_network()` function  in the `NeuralNetwork` class. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the layers of the neural network by calling the function `create_network()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the structure of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #1:** Give the value of the `in_features` of the first `nn.Linear` module (Index 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q1-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #2:** Give the value of the `out_features` of the last `nn.Linear` module (Index 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q2-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #3:** Give the total number of parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q3-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Initializing the model weights\n",
    "\n",
    "Open `neural_network.py` file and complete the `init_weights()` function in the `NeuralNetwork` class. This function initializes the weight of the network. Weights of a `nn.Linear` layer should be initialized from a normal distribution with mean `0` and standard deviation `0.1`. Bias terms of a `nn.Linear` layer should be initialized with a constant value of `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `init_weights()` function  in the `NeuralNetwork` class. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the weights of the neural network by calling the function `init_weights()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the weight of the 1st `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(network.layers[0].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The output of the previous cell should look like:\n",
    "\n",
    "```\n",
    "Parameter containing:\n",
    "tensor([[ x.xxxx, x.xxxx],\n",
    "        ...\n",
    "        [ x.xxxx, x.xxxx]], requires_grad=True)```\n",
    "        \n",
    "where `x.xxxx` is some float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #4:** Give the first value in the first row of the weights of the 1st `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q4-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the bias term of the 1st `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(network.layers[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The output of the previous cell should be:\n",
    "\n",
    "```\n",
    "Parameter containing:\n",
    "tensor([0., 0., 0., 0., 0.], requires_grad=True)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the weight of the 2nd `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #5:** Give the last value in the last row of the weights of the 2nd `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q5-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the bias term of the 2nd `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the weight of the 3rd `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #6:** Give the first value in the first row of the weights of the 3rd `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q6-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the bias term of the 3rd `nn.Linear` layer in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Forward propagation\n",
    "\n",
    "Forward propagation computes the output of each layer in the neural network. \n",
    "\n",
    "Open `neural_network.py` file and complete the `forward_manual()` function in the `NeuralNetwork` class. This function performs the forward propagation of the model, implemented manually. You have to manually implement the computation of the output of each linear layer in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `forward_manual()` function  in the `NeuralNetwork` class. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform forward propagation in the model by calling the function `forward_manual`. Pass the training instance in index `0`. Set `verbose=True`. Assign the return values to variables `scores` and `probabilities.`\n",
    "\n",
    "The function should display the output of the model for in each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** Let's call the pre-implemented `forward()` function of the model. This function also performs forward propagation, but using the operations defined in Pytorch modules. Thus, the output of our implementation of the `forward_manual()` function should be the same as the output of the `forward()` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #7:** What is the sum of the output of the last layer of the network? Why did we get that sum?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q7-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Getting the predictions\n",
    "\n",
    "Since this is a multinomial classification problem, the predicted class corresponds to the class with the highest probability.\n",
    "\n",
    "Open `neural_network.py` file and complete the `predict()` function in the `NeuralNetwork` class. This function returns the index of the class with the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the `predict()` function  in the `NeuralNetwork` class. Inline comments should help you in completing the contents of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get 10 random training instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "random_indices = np.random.randint(X_train.shape[0], \n",
    "                                   size=10)\n",
    "print('Random indices: ', random_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the scores and probabilities of the random training instances by calling the function `forward()`. Assign the return values to variables `scores` and `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the raw scores of random instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the probabilities of random instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predicted class by calling the function `predict()`. Store the predicted labels in the variable `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** All selected training examples are currently being classified under one class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #8:** Obviously, the predicted class received the highest probability among the other classes. Why are all selected training examples being classified under one class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q8-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Calculating the loss\n",
    "\n",
    "Since this is a multinomial classification problem, we need to use cross entropy loss.\n",
    "\n",
    "In PyTorch, we can use `nn.CrossEntropyLoss()` to calculate the cross entropy loss between the raw score output of the model and the target class. You may read the documentation [here](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `nn.CrossEntropy()` object. Do not change any default values set as parameter. Assign it to the variable `criterion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the target classes of the random training examples from the previous step. Convert the `torch.Tensor` to `torch.long`. This is because `nn.CrossEntropyLoss()` expects the target classes to be represented as a `long` and not `float`. Assign the return value to variable `target_classes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the loss and assign the return value to variable `loss`.\n",
    "\n",
    "To note, the loss function accepts the score output of the model, not the probabilities. Read the documentation to understand values to pass for the `input` and the `target` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loss: {:.4f}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #9:** What is the loss in this scenario? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q9-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Backward propagation for optimizing weights\n",
    "\n",
    "The next step would be to perform backward propagation to update the weights of the model. This will make the model better in classifying the input data. In PyTorch, we can call `backward()` function of the loss module to perform backward propagation. We also need to instantiate an optimizer to update the weights.\n",
    "\n",
    "Read this [documentation](https://pytorch.org/docs/stable/optim.html#taking-an-optimization-step) to learn the general pseudocode for updating weights in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Adam as our optimizer.\n",
    "\n",
    "Instantiate an `optim.Adam` object. Set the following parameters:\n",
    "- `params` = Set this to the parameters of your network\n",
    "- `lr` = `0.001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty the gradients of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the gradients through backward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the weight of the 1st `nn.Linear` layer in the network after updating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The output of the previous cell should be different from the initial set of weights, which is:\n",
    "\n",
    "```\n",
    "Parameter containing:\n",
    "tensor([[ x.xxxx, x.xxxx],\n",
    "        ...\n",
    "        [ x.xxxx, x.xxxx]], requires_grad=True)```\n",
    "        \n",
    "where `x.xxxx` is some float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #10:** What is the leftmost value in the weight tensor of the 1st `nn.Linear` layer in the network after updating? Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q10-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all steps together\n",
    "\n",
    "We will train the model using mini-batch gradient descent. \n",
    "\n",
    "Use the `data_loader.py` file that we implemented in the previous notebook. Import the `DataLoader` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate an `DataLoader` object. Pass the `X` and `y` of the train set and `32` as our `batch_size`. Assign it to the variable `data_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your network. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 400\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    # TODO: Get the batch for this epoch.\n",
    "    X_batch, y_batch = None\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "        \n",
    "        # TODO: Empty the gradients of the network.\n",
    "        \n",
    "        \n",
    "        # TODO: Forward propagation\n",
    "        scores, probabilities = None\n",
    "        \n",
    "        # TODO: Compute the loss\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward propagation\n",
    "        \n",
    "        \n",
    "        # TODO: Update parameters\n",
    "        \n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #11:** How many epochs did the model train before convergence?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q11-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #12:** What is the average loss at the last epoch? Limit to 6 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q12-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our trained network on the test data\n",
    "\n",
    "Set the network in test `eval` mode first, to avoid updating the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform forward propagation on the test data. Assign the return values to variables `scores` and `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the prediction results on the test data to see if our model can handle unseen instances. Store the predicted labels in the variable `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the ground truth labels with the predicted labels. Store the total number of correct predictions in the variable `num_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for the accuracy. Store the accuracy in the variable `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #13:** What is the accuracy of the network when evaluated on the test set? Express your answer in a floating point number from 0 to 1. Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q13-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the loss for each training epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = [i for i in range(len(losses))]\n",
    "y_values = losses\n",
    "\n",
    "plt.plot(x_values, y_values)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss for each training epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #14:** Around what epoch did our training converge, i.e., when there are minimal changes in the value of the loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q14-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset\n",
    "We will use the Iris dataset as our dataset. Each instance represents an Iris flower using 4 distinct features:\n",
    "- `sepal_length` - length of the sepal in centimeters\n",
    "- `sepal_width` - width of the sepal in centimeters\n",
    "- `petal_length` - length of the petal in centimeters\n",
    "- `petal_width` - width of the petal in centimeters\n",
    "\n",
    "Iris flowers can be 3 divided into different classes, which are:\n",
    "- `Iris-setosa` - class `0`\n",
    "- `Iris-versicolor` - class `1`\n",
    "- `Iris-virginica` - class `2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load `Iris.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    'Iris-setosa': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-virginica': 2\n",
    "}\n",
    "\n",
    "with open('Iris.csv', 'r') as csv_file:\n",
    "    raw_data = csv.reader(csv_file)\n",
    "    X_iris = np.empty((0, 4), float)\n",
    "    y_iris = np.empty((0, 1), int)\n",
    "    for row in raw_data:\n",
    "        X_iris = np.vstack([X_iris, np.array([float(row[0]),     # column for sepal_length\n",
    "                                              float(row[1]),     # column for sepal_width\n",
    "                                              float(row[2]),     # column for petal_length\n",
    "                                              float(row[3])])])  # column for petal_width\n",
    "        \n",
    "        y_iris = np.append(y_iris, np.array([classes[row[4]]]))  # column for class\n",
    "\n",
    "# This transforms the vector of length N into a matrix with shape (N, 1)\n",
    "y_house = np.expand_dims(y_iris, 1) \n",
    "\n",
    "print('Training data shape:', X_iris.shape)\n",
    "print('Ground truth values shape:', y_iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the number of instances per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris_0 = X_iris[y_iris == 0]\n",
    "X_iris_1 = X_iris[y_iris == 1]\n",
    "X_iris_2 = X_iris[y_iris == 2]\n",
    "\n",
    "print('Number of class 0:', len(X_iris_0))\n",
    "print('Number of class 1:', len(X_iris_1))\n",
    "print('Number of class 2:', len(X_iris_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 50 instances for each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the dataset into train and test set. The test set will contain 10 instances for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "# Select 10 `class 0` instances\n",
    "selected_0 = np.random.choice(np.arange(len(X_iris_0)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 1` instances\n",
    "selected_1 = np.random.choice(np.arange(len(X_iris_1)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Select 10 `class 2` instances\n",
    "selected_2 = np.random.choice(np.arange(len(X_iris_2)),\n",
    "                              size=10,\n",
    "                              replace=False)\n",
    "\n",
    "# Form the test set\n",
    "X_test = np.concatenate((X_iris_0[selected_0],\n",
    "                         X_iris_1[selected_1],\n",
    "                         X_iris_2[selected_2]))\n",
    "y_test = np.concatenate((np.array([0 for _ in range(10)]),\n",
    "                         np.array([1 for _ in range(10)]),\n",
    "                         np.array([2 for _ in range(10)])))\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining 120 instances will be a part of the train set, where each class has 40 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((np.delete(X_iris_0, selected_0, 0),\n",
    "                          np.delete(X_iris_1, selected_1, 0),\n",
    "                          np.delete(X_iris_2, selected_2, 0)))\n",
    "y_train = np.concatenate((np.array([0 for _ in range(40)]),\n",
    "                          np.array([1 for _ in range(40)]),\n",
    "                          np.array([2 for _ in range(40)])))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `np.ndarray` arrays to `torch.Tensor`. We use `torch.Tensor` in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `X_train` to the datatype `torch.Tensor` and assign the return value to variable `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `y_train` to the datatype `torch.Tensor` and assign the return value to variable `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `X_test` to the datatype `torch.Tensor` and assign the return value to variable `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the variable `y_test` to the datatype `torch.Tensor` and assign the return value to variable `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the training pipeline\n",
    "\n",
    "Set-up the following:\n",
    "- Network\n",
    "- Optimizer\n",
    "- Loss function\n",
    "- Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `NeuralNetwork` object. Set the following parameters:\n",
    "- `list_hidden` = (5, 10)\n",
    "- `activation` = `sigmoid`\n",
    "\n",
    "Here, we are creating a Neural Network with two hidden layers, where there are 5 units in the first layer and 10 units in the second layer.\n",
    "\n",
    "Set the other parameters according to the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the network and initialize the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the structure of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #15:** Give the value of the `in_features` of the first `nn.Linear` module (Index 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q15-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #16:** Give the value of the `out_features` of the last `nn.Linear` module (Index 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q16-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Adam as our optimizer.\n",
    "\n",
    "Instantiate an `optim.Adam` object. Set the following parameters:\n",
    "- `params` = Set this to the parameters of your network\n",
    "- `lr` = `0.001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `nn.CrossEntropy()` object. Do not change any default values set as parameter. Assign it to the variable `criterion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the model using mini-batch gradient descent. \n",
    "\n",
    "Instantiate a `DataLoader` object. Pass the `X` and `y` of the train set and `32` as our `batch_size`. Assign it to the variable `data_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "\n",
    "Train your network. Complete the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 0\n",
    "max_epochs = 300\n",
    "is_converged = False\n",
    "previous_loss = 0\n",
    "losses = []\n",
    "\n",
    "# For each epoch\n",
    "while e < max_epochs and is_converged is not True:\n",
    "    \n",
    "    current_epoch_loss = 0\n",
    "    \n",
    "    # TODO: Get the batch for this epoch.\n",
    "    X_batch, y_batch = None\n",
    "    \n",
    "    # For each batch\n",
    "    for X, y in zip(X_batch, y_batch):\n",
    "        X = torch.Tensor(X)\n",
    "        y = torch.Tensor(y).to(torch.long)\n",
    "        \n",
    "        # TODO: Empty the gradients of the network.\n",
    "        \n",
    "        \n",
    "        # TODO: Forward propagation\n",
    "        scores, probabilities = None\n",
    "        \n",
    "        # TODO: Compute the loss\n",
    "        loss = None\n",
    "        \n",
    "        # TODO: Backward propagation\n",
    "        \n",
    "        \n",
    "        # TODO: Update parameters\n",
    "        \n",
    "        \n",
    "        current_epoch_loss += loss.item()\n",
    "    \n",
    "    average_loss = current_epoch_loss / len(X_batch)\n",
    "    losses.append(average_loss)\n",
    "    \n",
    "    # Display the average loss per epoch\n",
    "    print('Epoch:', e + 1, '\\tLoss: {:.6f}'.format(average_loss))\n",
    "    \n",
    "    if abs(previous_loss - loss) < 0.00000005:\n",
    "        is_converged = True\n",
    "    else:\n",
    "        previous_loss = loss\n",
    "        e += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try our trained network on the test data\n",
    "\n",
    "Set the network in test `eval` mode first, to avoid updating the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform forward propagation on the test data. Assign the return values to variables `scores` and `probabilities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the prediction results on the test data to see if our model can handle unseen instances. Store the predicted labels in the variable `predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the ground truth labels with the predicted labels. Store the total number of correct predictions in the variable `num_correct`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute for the accuracy. Store the accuracy in the variable `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #17:** What is the accuracy of the network when evaluated on the test set? Express your answer in a floating point number from 0 to 1. Limit to 4 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Q17-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>fin</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
