{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Exercise\n",
    "This exercise will guide you in implementing the Decision Trees. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with \"A: \" on them. The answer must strictly consume **one to two lines** only.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* There are commented markdown cells that have crumbs. Do not delete them or separate them from the cell originally directly below it.  \n",
    "* You may add new cells for \"scrap work\" as long as the crumbs are not separated from the cell below it.\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You are expected to understand the data set loading and processing separately from this class.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree classifier\n",
    "\n",
    "For this first section, we will create a decision tree to predict the flower species from the iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:**\n",
    "The iris data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Sepal length in cm\n",
    "2. Sepal width in cm\n",
    "3. Petal length in cm\n",
    "4. Petal width in cm\n",
    "5. Class (Species):\n",
    "    - Iris Setosa\n",
    "    - Iris Versicolour\n",
    "    - Iris Virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using pandas to import our csv data into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv file into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the feature columns for X, and the label column for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test sets. Set the `random_state` to `0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our classification tree\n",
    "We will be using sklearn's `DecisionTreeClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a classification tree here but do not make any predictions in this cell yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtc = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our lecture, we learned that trees can overfit by creating a separate node for every single configuration of feature values possible. Let's see if this is true by running predictions on our training set.\n",
    "\n",
    "Run predictions on the train set, get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_train = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be computing for the accuracy multiple times in this notebook, so let's create a function for this.\n",
    "\n",
    "`compute_accuracy()` will compute for the accuracy given two vectors of equal length\n",
    "\n",
    "__Inputs:__\n",
    "- `predictions`: A numpy array of shape `(N,)` consisting of `N` samples representing the predicted values\n",
    "- `actual`: A numpy array of shape `(N,)` consisting of `N` samples representing the actual (target) values\n",
    "\n",
    "__Outputs:__\n",
    "- `accuracy`: A scalar representing the percentage of elements where `predictions` and `actual` match out of the total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    # write code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training accuracy: \", compute_accuracy(y_train, predictions_train),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** A decision tree without regularization should be able to achieve 100% accuracy on the training set.\n",
    "\n",
    "If not, you might be seeing a 99.9999% accuracy. But if you look at the predictions, you will see that it got all the train set predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our model does with the test set. Run predictions on the test set, and get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Testing accuracy: \", compute_accuracy(y_test, predictions),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #1:__ What could possibly contribute to the difference in the train and test error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What could possibly contribute to the difference in the train and test error?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the tree\n",
    "\n",
    "You can also read more about the following code here: https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py \n",
    "\n",
    "The code just reconstructs the tree given the model/estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_tree(clf):\n",
    "    n_nodes = clf.tree_.node_count\n",
    "    children_left = clf.tree_.children_left\n",
    "    children_right = clf.tree_.children_right\n",
    "    feature = clf.tree_.feature\n",
    "    threshold = clf.tree_.threshold\n",
    "    values = clf.tree_.value\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print(\n",
    "        \"The binary tree structure has {n} nodes and has \"\n",
    "        \"the following tree structure:\\n\".format(n=n_nodes)\n",
    "    )\n",
    "    for i in range(n_nodes):\n",
    "        if is_leaves[i]:\n",
    "            print(\n",
    "                \"{space}node={node} is a leaf node, values: {values}.\".format(\n",
    "                    space=node_depth[i] * \"\\t\", node=i, values=values[i]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            print(\n",
    "                \"{space}node={node} is a split node: \"\n",
    "                \"go to node {left} if X[:, {feature}] <= {threshold} \"\n",
    "                \"else to node {right}.\".format(\n",
    "                    space=node_depth[i] * \"\\t\",\n",
    "                    node=i,\n",
    "                    left=children_left[i],\n",
    "                    feature=feature[i],\n",
    "                    threshold=threshold[i],\n",
    "                    right=children_right[i],\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_tree(dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #2:__ How many nodes are present in the tree above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: How many nodes are present in the tree above?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #3:__ We have the following features: `sepal_length`, `sepal_width`, `petal_length`, `petal_width`. Which feature does the root node look at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: We have the following features: sepal_length, sepal_width, petal_length, petal_width. Which feature does the root node look at?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #4:__ If a test data gets categorized to node=12, which among these classes will it fall under: setosa, versicolor, or virginica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: If a test data gets categorized to node=12, which among these classes will it fall under: setosa, versicolor, or virginica?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(dtc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree.export_graphviz(dtc,out_file='tree.dot')                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a graph of the tree, open `tree.dot` and paste its contents in <a src=\"http://webgraphviz.com/\">webgraphviz.com</a>. You'll end up with a similar tree like the one below:\n",
    "\n",
    "<img src=\"https://i.imgur.com/E7UJJZk.png\" width=\"300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees regressor\n",
    "For regression, we will generate a dummy dataset following a sin curve so we can visualize the results. This will also allow us to visualize how our model does regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 300\n",
    "np.random.seed(1)\n",
    "X = np.expand_dims(np.random.uniform(-np.pi,np.pi, n_samples),1)\n",
    "y = np.sin(2*X) + np.random.randn(n_samples,1)*0.3\n",
    "\n",
    "num_items = X.shape[0]\n",
    "randIdx = np.arange(num_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our dataset. Set the `random_seed` to `42` so your results matches the sanity check below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X_train, X_test, y_train, y_test = None\n",
    "\n",
    "print(\"X_train shape : \", X_train.shape)\n",
    "print(\"y_train shape : \", y_train.shape)\n",
    "print(\"X_test shape : \", X_test.shape)\n",
    "print(\"y_test shape : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need our `y` as vectors later on, so let's reshape/squeeze that extra dimension off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.squeeze(y_train)\n",
    "y_test = np.squeeze(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the dataset\n",
    "To help you visualize our data, it looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our regression tree\n",
    "Here we will use `DecisionTreeRegressor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build our classifier, and make it run predictions on our train data. Use the default hyperparameters for our regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtr = None\n",
    "\n",
    "\n",
    "train_predictions = None\n",
    "train_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate for the mean squared error and the mean absolute error. We will make a function for both of these because will be computing for the `mse` and `mae` multiple times in the notebook.\n",
    "\n",
    "___\n",
    "\n",
    "`compute_mse()` will compute for the mean squared error given two vectors of equal length\n",
    "\n",
    "__Inputs:__\n",
    "- `predictions`: A numpy array of shape `(N,)` consisting of `N` samples representing the predicted values\n",
    "- `actual`: A numpy array of shape `(N,)` consisting of `N` samples representing the actual (target) values\n",
    "\n",
    "__Outputs:__\n",
    "- `mse`: A scalar representing the mean squared error between `predictions` and `actual`\n",
    "\n",
    "___\n",
    "\n",
    "`compute_mae()` will compute for the mean absolute error given two vectors of equal length\n",
    "\n",
    "__Inputs:__\n",
    "- `predictions`: A numpy array of shape `(N,)` consisting of `N` samples representing the predicted values\n",
    "- `actual`: A numpy array of shape `(N,)` consisting of `N` samples representing the actual (target) values\n",
    "\n",
    "__Outputs:__\n",
    "- `mae`: A scalar representing the mean absolute error between `predictions` and `actual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(predictions, actual):\n",
    "    # write code here\n",
    "    return None\n",
    "\n",
    "def compute_mae(predictions, actual):\n",
    "    # write code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = compute_mse(train_predictions, y_train)\n",
    "print(\"Mean Squared Error :\", mse)\n",
    "\n",
    "mae = compute_mae(train_predictions, y_train)\n",
    "print(\"Absolute Relative Error :\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"gray\")\n",
    "plt.scatter(X_train, train_predictions, color=\"red\", marker=\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #5:__ How can you describe the accuracy of the model on the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: How can you describe the chart above showing y_train vs train_predictions?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(dtr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make it run predictions on our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "test_predictions = None\n",
    "\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = compute_mse(test_predictions, y_test)\n",
    "print(\"Mean Squared Error :\", mse)\n",
    "\n",
    "mae = compute_mae(test_predictions, y_test)\n",
    "print(\"Absolute Relative Error :\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** You should see values like the following:\n",
    "```\n",
    "Mean Squared Error : 0.260963821953\n",
    "Absolute Relative Error : 0.414856812765\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize how the our predictions fare against the actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(X_test, y_test, label='Ground Truth')\n",
    "plt.scatter(X_test, test_predictions, label='Predicted')\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularizing decision trees\n",
    "In the absence of regularization, the decision tree will memorize the training set and achieve 0% error. While this is good in terms of bias, it may not generalize well to never before seen data (variance problem)\n",
    "\n",
    "Let's modify our model to include three ways of regularization:\n",
    "- **Minimum samples split**: If the remaining samples are less than the specifed value then we stop splitting and make it a leaf node\n",
    "- **Max depth**: Restricts the maximum depth of the trees\n",
    "- **Minimum impurity decrease**: If the impurity decrease is less than the specified value then we stop splitting and make it a leaf node.\n",
    "- **Max leaf node**: If the number of leaf nodes is met then we stop splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use this test set for the visualization below, so use this as your test set for the loop below. It follows the same sin function as our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vis = np.expand_dims(np.linspace(-np.pi,np.pi,300),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_vis = np.sin(2*X_test_vis) + np.random.randn(n_samples,1)*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test_vis,y_test_vis, color=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing with minimum samples split\n",
    "\n",
    "Let's apply different minimum samples splits to your model. Let's try it with these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_split_vals = [2, 4, 6, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the following code work, __you have to do the following per iteration__:\n",
    "1. Create a decision tree regressor following the minimum samples split value for that iteration\n",
    "1. Fitthe model to your train data and the training labels/outputs\n",
    "1. Get the trained model to make predictions on `X_test_vis`\n",
    "1. Plot `X_test_vis` (x-coordinate) relative to the predictions (y-coordinate) made by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some plotting stuff\n",
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "for val in min_samples_split_vals:\n",
    "    # write code here\n",
    "    dtr = None\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,2,plt_ctr)\n",
    "    \n",
    "    #wWrite code here\n",
    "    predictions = None\n",
    "    \n",
    "    plt.scatter(X_test_vis, predictions)\n",
    "    \n",
    "    plt.title(\"Min samples = \"+ str(val))\n",
    "    \n",
    "    plt_ctr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:**\n",
    "Your graph should like the one below:\n",
    "<img src=\"https://imgur.com/Wibqyx4.png\" width=\"400px\">\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the number of minimum samples, the predictions for close/nearby x values tend to get the same y-value. 'Minimum samples' refers to the minimum number of instances/samples in a node needed to split it. Increasing the number of samples tells the model to stop splitting early on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #6:__ For this particular dataset, how many nodes can we expect the final tree to have if we set the minimum sample split to `10,000?`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: For this particular dataset, how many nodes can we expect the final tree to have if we set the minimum sample split to 10,000?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing with maximum depth\n",
    "\n",
    "Let's apply different maximum depths to your model. Let's try it with these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth_vals = [2, 4, 6, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the following code work, __you have to do the following per iteration__:\n",
    "1. Create a decision tree regressor following the maximum depth value for that iteration\n",
    "1. Fit the model to your train data and the training labels/outputs\n",
    "1. Get the trained model to make predictions on `X_test_vis`\n",
    "1. Plot `X_test_vis` (x-coordinate) relative to the predictions (y-coordinate) made by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,12))\n",
    "for val in max_depth_vals:\n",
    "    # write code here\n",
    "    dtr = None\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,2,plt_ctr)\n",
    "    \n",
    "    # write code here\n",
    "    predictions = None\n",
    "    \n",
    "    plt.scatter(X_test_vis, predictions)\n",
    "    \n",
    "    plt.title(\"Max depth = \"+ str(val))\n",
    "    \n",
    "    plt_ctr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** The higher the max depth, the more unique labels you will get. (Inverse of minimum spits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the maximum depth, the predictions for close/nearby x values tend to get the different y-values. An increase in maximum depth tells the model it's okay to keep splitting more nodes. Having a small max depth tells the model to stop after it reachers the specified depth/height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing with minimum impurity decrease\n",
    "\n",
    "Let's apply different minimum impurity decrease to your model. Let's try it with these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_impurity_vals = [0, 0.0001, 0.001, 0.01, 0.1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the following code work, __you have to do the following per iteration__:\n",
    "1. Create a decision tree regressor following the minimum impurity decrease value for that iteration\n",
    "1. Fit the model to your train data and the training labels/outputs\n",
    "1. Get the trained model to make predictions on `X_test_vis`\n",
    "1. Plot `X_test_vis` (x-coordinate) relative to the predictions (y-coordinate) made by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "for val in min_impurity_vals:\n",
    "    # write code here\n",
    "    dtr = None\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,2,plt_ctr)\n",
    "    \n",
    "    # write code here\n",
    "    predictions = None\n",
    "    \n",
    "    plt.scatter(X_test_vis, predictions)\n",
    "    \n",
    "    plt.title(\"Min impurity decrease= \"+ str(val))\n",
    "    \n",
    "    plt_ctr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** You should see an output with a similar pattern as minimum samples split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the minimum impurity decrease, the predictions for close/nearby x values tend to get the same y-value. Having a lower impurity decrease tells the model to reach this level of minimum impurity before a node stop branching out. So **having a lower impurity requires the model to keep on splitting until every node achieves the minimum impurity**. With an imposed high impurity decrease, the model can stop splitting if it does not lower the impurity in the next split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularizing with max leaf nodes \n",
    "\n",
    "Let's apply different max leaf nodes to your model. Let's try it with these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_leaf_vals = [3, 5, 10, 20, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the following code work, __you have to do the following per iteration__:\n",
    "1. Create a decision tree regressor following the max leaf nodes value for that iteration\n",
    "1. Fit the model to your train data and the training labels/outputs\n",
    "1. Get the trained model to make predictions on `X_test_vis`\n",
    "1. Plot `X_test_vis` (x-coordinate) relative to the predictions (y-coordinate) made by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_ctr = 1\n",
    "plt.figure(figsize=(15,12))\n",
    "\n",
    "for val in max_leaf_vals:\n",
    "    # write code here\n",
    "    dtr = None\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,2,plt_ctr)\n",
    "    \n",
    "    # write code here\n",
    "    predictions = None\n",
    "    \n",
    "    plt.scatter(X_test_vis, predictions)\n",
    "    \n",
    "    plt.title(\"Max leaf nodes= \"+ str(val))\n",
    "    \n",
    "    plt_ctr += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check:** You should see an output with a similar pattern as max depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the max leaf nodes, the predictions for close/nearby x values tend to get the different y-values. Why? Increasing the max leaf nodes allow our model to split data into their own value node, while having a small max leaf nodes forces our model to stop splitting early."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "Now that we have learned the hyperparameters we can control in our tree model, let's try to find out the best hyperparameters for our model using cross validation. We will also use randomized search to aid in hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning a decision tree regressor\n",
    "Note that we will be using the same sin wave data for the following section. \n",
    "\n",
    "We already separated our training data (`X_train`, `y_train`) from our hold-out test set (`X_test`, `y_test`) so we can go straight to modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model\n",
    "Let's define our base model/estimator. Since this is a regression task, we should make a `DecisionTreeRegressor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtr = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following section, we will define our hyperparameters. For now, set the following hyperparameter choices:\n",
    "\n",
    "__Hyperparameters__:\n",
    "- minimum impurity decrease could be 0.001, 0.01, 0.05, 0.1, 0.3, 0.5\n",
    "- max depth could be 5, 10, 20, 30\n",
    "- minimum samples split could be 2, 4, 6, 10, 15, 20\n",
    "- max leaf nodes could be 3, 5, 10, 20, 50, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "hyperparameters = [\n",
    "    {\n",
    "        #'<name>': <value>,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our `RandomizedSearchCV` object, and give it our base estimator and hyperparameters. Set the number of estimators to `50`, and the number of cross validation folds to `5`. Set the `random_state` to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "rsr = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train our models on our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best hyperparameters found by our randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can make a new estimator with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtr = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the estimator on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, get the predictions and the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions = None\n",
    "\n",
    "print(\"MSE: \", compute_mse(y_train, predictions))\n",
    "print(\"MAE: \", compute_mae(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #7:__ What is the training mean squared error of our best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the training mean squared error of our best model?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #8:__ What is the training mean absolute error of our best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the training mean absolute error of our best model?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ We could directly use `rsr` to make predictions as it refits to our provided data by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing how our model performs on the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train, y_train, color=\"gray\")\n",
    "plt.scatter(X_train, predictions, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing phase\n",
    "\n",
    "Now, let's test our model on our test data. If we tuned our models correctly, we should be able to get a comparable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions = None\n",
    "\n",
    "print(\"MSE: \", compute_mse(y_test, predictions))\n",
    "print(\"MAE: \", compute_mae(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** You should get the following results:\n",
    "```\n",
    "MSE:  0.14689992394675497\n",
    "MAE:  0.29875019754298676\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing how our model performs on the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test, y_test, color=\"gray\")\n",
    "plt.scatter(X_test, predictions, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning a decision tree classifier\n",
    "We will bring back the iris dataset from before to train our decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing our data\n",
    "We get our `X` and separate it from our target output `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating out our hold-out test set\n",
    "We will use the test set later to check how well our model is doing after we perform hyperparameter tuning. For this split, make sure we stratify our data based on the species. Set the `random_state` to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know if the stratification worked, the following code should show an equal number of counts per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Training data label counts:\")\n",
    "print(np.array([unique, counts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sanity check:__ You should see the following\n",
    "```\n",
    "Training data label counts:\n",
    "[[ 0  1  2]\n",
    " [35 35 35]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Test data label counts:\")\n",
    "print(np.array([unique, counts]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sanity check:__ You should see the following\n",
    "```\n",
    "Training data label counts:\n",
    "[[ 0  1  2]\n",
    " [15 15 15]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our model\n",
    "Since the task is framed as a classification problem, we will create a `DecisionTreeClassifier` as our estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following code, we will define our hyperparameters. For now, set the following hyperparameter choices:\n",
    "\n",
    "__Hyperparameters__:\n",
    "- criterion could either be `gini` or `entropy`\n",
    "- max depth could be 5, 10, 20, 30\n",
    "- minimum samples split could be 2, 4, 6, 10, 15, 20\n",
    "- max leaf nodes could be 3, 5, 10, 20, 50, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "hyperparameters = [\n",
    "    {\n",
    "        #'<name>': <value>,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our `RandomizedSearchCV` object, and give it our base estimator and hyperparameters. Set the number of estimators to `50`, and the number of cross validation folds to `5`. Set the `random_state` to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "rsc_iris = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our models to our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the best parameters found in our hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also see the results of each model (and their hyperparameters) using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rsc_iris.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To easily see the results, let's view it as a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this code will help the model not truncate the hyperparameters section\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "rsc_results = pd.DataFrame(rsc_iris.cv_results_)\n",
    "rsc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the randomized search's best estimator index to quickly get the entry of the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "best_index = None\n",
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_results.loc[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best accuracy achieved by a best model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "best_acc = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #9:__ What is the accuracy achieved by our best estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the accuracy achieved by our best estimator?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get the `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rsc_iris.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing phase\n",
    "Now that we have our best model, let's see how our best model performs on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute for the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy is : \", compute_accuracy(predictions, y_test), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #10:__ What is the test accuracy of our tuned model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the test accuracy of our tuned model?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Decision trees are models that partition your data one feature and one feature threshold/value at a time. This creates a tree that acts like a step-by-step \"flowchart\" of what to label a new test instance. It is also for this reason that decision trees are non-linear, the end result is a string of decisions across different features. Because of the visualization we get from decision trees, we can thoroughly understand why an instance labelled that way it was by following the \"prediction path\" the test instance made in the model. (However, this is only true for trees that are shallow. Complex trees are also hard to interpret)\n",
    "\n",
    "Decision trees are easy to overfit: it can just continue to split/branch off until each instance has its own separate leaf node. We can apply regularization methods like the ones we use above to prevent them from overfitting.\n",
    "\n",
    "Overfitting, as we have learned, is a sign of a high variance model. In the next lesson, we will learn more about another way of reducing our model's variance (and bias) error with ensemble models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>fin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->\n",
    "\n",
    "<sup>made/compiled by daniel stanley tan & courtney anne ngo üê∞ & thomas james tiam-lee</sup> <br>\n",
    "<sup>for comments, corrections, suggestions, please email:</sup><sup> danieltan07@gmail.com & courtneyngo@gmail.com & thomasjamestiamlee@gmail.com</sup><br>\n",
    "<sup>please cc your instructor, too</sup>\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
