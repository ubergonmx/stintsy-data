{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**<span style=\"color:#448844\">Note</span>** This notebook is meant to be interactive. Launch this notebook in Jupyter to see its full potential.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Aaron Palpallatoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Section: S11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models Exercise\n",
    "This exercise will guide you in implementing 3 ensemble models: random forest (bagging), xgboost (boosting), and adaboost (boosting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "* Read each cell and implement the TODOs sequentially. The markdown/text cells also contain instructions which you need to follow to get the whole notebook working.\n",
    "* Do not change the variable names unless the instructor allows you to.\n",
    "* Answer all the markdown/text cells with \"A: \" on them. The answer must strictly consume one line only.\n",
    "* You are expected to search how to some functions work on the Internet or via the docs. \n",
    "* There are commented markdown cells that have crumbs. Do not delete them or separate them from the cell originally directly below it.  \n",
    "* You may add new cells for \"scrap work\" as long as the crumbs are not separated from the cell below it.\n",
    "* When you are asked to tweak the parameters/code, make sure you bring it back to the originally requested code or place the tweaked code in a \"scrap\" cell.\n",
    "* The notebooks will undergo a \"Restart and Run All\" command, so make sure that your code is working properly.\n",
    "* You are expected to understand the data set loading and processing separately from this class.\n",
    "* You may not reproduce this notebook or share them to anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# %matplotlib inline\n",
    "# plt.style.use('ggplot')\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "# plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "In this first section, we will load two datasets: <a href=\"https://archive-beta.ics.uci.edu/ml/datasets/186\">the wine quality dataset</a> and <a href=\"https://archive-beta.ics.uci.edu/ml/datasets/20\">the census income dataset</a>. Both datasets are available on animoopenspace, so please download those two files and make sure they are in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access both datasets and more in the UCI machine learning repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Our regression dataset: wine quality__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality = pd.read_csv(\"wine_quality.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Our classification dataset: census income dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_income = pd.read_csv(\"census_income.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine quality dataset\n",
    "The wine dataset is composed of two files, one for red wine and another for white wine. We will only load the red dataset, but you can load both if you like. We want to know the quality of the wine and assign a score from 0-10. This can be treated as a classification or regression task. There are 1,599 instances in the red wine dataset, and 4,898 instances in the white dataset.\n",
    "\n",
    "**Attribute Information:**\n",
    "- fixed acidity\n",
    "- volatile acidity\n",
    "- citric acid\n",
    "- residual sugar\n",
    "- chlorides\n",
    "- free sulfur dioxide\n",
    "- total sulfur dioxide\n",
    "- density\n",
    "- pH\n",
    "- sulphates\n",
    "- alcohol\n",
    "- quality: a score between 0-10 that we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wine_quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census income dataset\n",
    "This data was extracted from the US census bureau database found at https://archive-beta.ics.uci.edu/ml/datasets/census+income. The goal of the original study was to determine whether a person makes more than or less than USD 50,000 a year given some other info available in the census. There are technically two files, one each for the training data and the test data, but this notebook only loads the training data.\n",
    "\n",
    "**Attribute Information:**\n",
    "- age\n",
    "- workclass\n",
    "- fnlwgt (sampling weight -- will be removed)\n",
    "- education\n",
    "- educationnum\n",
    "- maritalstatus\n",
    "- occupation\n",
    "- relationship\n",
    "- race\n",
    "- sex\n",
    "- capitalgain\n",
    "- capitalloss\n",
    "- hoursperweek\n",
    "- nativecountry\n",
    "- label: either '<=50k' or '>50k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This csv file does not include the column names, so let's add it in first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_income.columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationnum', 'maritalstatus', 'occupation', 'relationship','race','sex','capitalgain','capitalloss', 'hoursperweek', 'nativecountry', 'label']\n",
    "df_census_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_income = df_census_income.drop([\"fnlwgt\"], axis=1)\n",
    "df_census_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees can handle both categorical and numerical features in theory, but sklearn's implementation cannot handle categorical features. We will fix this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the regression models\n",
    "We will make 3 regression models: a simple decision tree, a random forest regressor, and a `xgboost` model. All will be trained on the wine quality dataset.\n",
    "\n",
    "Let's prepare out `X` feature dataset and `y` label vector. Extract the feature columns for `X`, and the label column for `y`\n",
    "\n",
    "__Hint__ : For `X`, look up `pandas.drop()`. You can convert a DataFrame to a matrix using `your_dataframe.values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X_wine =  None\n",
    "y_wine = None\n",
    "\n",
    "print(X_wine.shape)\n",
    "print(y_wine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split `X_wine` and `y_wine` into training and test sets. Set the random state to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X_train_wine, X_test_wine, y_train_wine, y_test_wine = None\n",
    "\n",
    "print(\"wine train and test split\")\n",
    "print(\"X_train_wine: \", X_train_wine.shape)\n",
    "print(\"y_train_wine: \", y_train_wine.shape)\n",
    "print(\"X_test_wine: \", X_test_wine.shape)\n",
    "print(\"y_test_wine: \", y_test_wine.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple decision tree\n",
    "\n",
    "We'll train a decision tree regressor first, then compare its results to the ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# DecisionTreeRegressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a normal regression tree using the default hyperparameters, and train it with our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtr = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_train = None\n",
    "\n",
    "predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that at this point, the model interpreted our label as a categorical discrete value (1, 2, 3, ...), which is why we don't get decimal values. However, we know that this should be a numerical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate for the mean squared error. We will make a function for both of these because will be computing for the `mse` and `mae` multiple times in the notebook.\n",
    "\n",
    "___\n",
    "\n",
    "`compute_rmse()` will compute for the root mean squared error given two vectors of equal length\n",
    "\n",
    "__Inputs:__\n",
    "- `predictions`: A numpy array of shape `(N,)` consisting of `N` samples representing the predicted values\n",
    "- `actual`: A numpy array of shape `(N,)` consisting of `N` samples representing the actual (target) values\n",
    "\n",
    "__Outputs:__\n",
    "- `mse`: A scalar representing the root mean squared error between `predictions` and `actual`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(predictions, actual):\n",
    "    # write code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the train RMSE of the model's predictions vs the ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_rmse(predictions_train, y_train_wine)\n",
    "\n",
    "print(\"Decision tree regressor training RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**: You should get an RMSE of 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #1**: Why are we getting an RMSE of 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: Why are we getting an RMSE of 0?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #2:__ In what situation can decision tree regressors not get an RMSE of 0 despite overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: In what situation can decision tree regressors not get an RMSE of 0 despite overfitting?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our model on the test set. Run predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_test = None\n",
    "\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_rmse(predictions_test, y_test_wine)\n",
    "\n",
    "print(\"Decision tree regressor test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity Check**: The RMSE here should be higher than the training data RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Visualizing our decision tree regressor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree.plot_tree(dtr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a random forest regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a random forest model with 300 base models. You can check out the other parameters in `RandomForestRegressor` and tweak it later. For now, create a random forest with `300` base models and train it. Set the random state to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "rfr = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_train = None\n",
    "\n",
    "predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questoin #2:** Why are we getting floats and not integers as our predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the train RMSE of the model's predictions vs the ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_rmse(predictions_train, y_train_wine)\n",
    "\n",
    "print(\"Random forest regressor test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The RMSE should be ~0.2152."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #3:** Random forests are supposed to have a lower loss than decision trees. Why is our random forest's RMSE larger than our decision tree's RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: Random forests are supposed to have a lower loss than decision trees. Why is our random forest's RMSE larger than our decision tree's RMSE?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try our random forest's performance on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_test = None\n",
    "\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = compute_rmse(predictions_test, y_test_wine)\n",
    "\n",
    "print(\"Random forest regressor test RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare our random forest's RMSE compared to the decision tree's RMSE on the test set. The random forest should have a smaller test RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #4:__ What is the test RMSE of our random forest regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the test RMSE of our random forest regressor?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #5:** Why is our random forest's test RMSE smaller than the decision tree's RMSE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: Why is our random forest's test RMSE smaller than the decision tree's RMSE?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's visualize one random forest base model.** If you remember, in our lecture, we do not mind a overfit base model. Let's see the effect here now.\n",
    "\n",
    "In the following cell, Get the fist base model from the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "estimator = None\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will generate one estimator/base model. Note that each model image will be around ~12MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='rf_regression_base_tree.dot', \n",
    "                feature_names = df_wine_quality.drop(columns=\"quality\").columns,\n",
    "                class_names = df_wine_quality[\"quality\"].unique(),\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'rf_regression_base_tree.dot', '-o', 'rf_regression_base_tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'rf_regression_base_tree.png')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"> __Note:__ You need to run the code above to answer the question below, __but make sure that you delete the code cell before you submit your notebook. Failure to delete it will result in major deductions__ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #6:__ How will you describe the figure shown above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: How will you describe the figure shown above?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying what you have learned from the previous notebook, get the base estimator's number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the base estimator's max tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #7:__ How many nodes does this estimator have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: How many nodes does this estimator have?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #8:__ What is the max depth of this estimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the max depth of this estimator?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the classifier models\n",
    "We will make 3 models: a simple decision tree, a random forest classifier, and a adaboost model. All models will be trained on the census income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "While decision trees can handle a mix of categorical and numerical feature data in theory, sklearn's implementation of decision trees and random forests can unfortunately only handle numerical features. \n",
    "\n",
    "To make our model still accept the entirety of our census income dataset, we will **label encode** our categorical data. **Label encoding** means that we will be assigning an integer to each possible class in one feature, and use these label-numbers as our new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top}\n",
    ".tg .tg-baqh{text-align:center;vertical-align:top}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-1wig\">fruit</th>\n",
    "    <th class=\"tg-1wig\">label_encoded_fruit</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">apple</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">banana</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">orange</td>\n",
    "    <td class=\"tg-baqh\">3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">apple</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">apple</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">orange</td>\n",
    "    <td class=\"tg-baqh\">3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">banana</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">banana</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">banana</td>\n",
    "    <td class=\"tg-baqh\">2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">apple</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">apple</td>\n",
    "    <td class=\"tg-baqh\">1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-baqh\">orange</td>\n",
    "    <td class=\"tg-baqh\">3</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above shows a column called `fruit`. After label encoding the`fruit` column, we assign each fruit to the following integers:\n",
    "<center> apple: 1 </center>\n",
    "<center> banana: 2 </center>\n",
    "<center> orange: 3</center>\n",
    "This gives us the new column `label_encoded_fruit`. \n",
    "\n",
    "Fortunately, sklearn has a pre-defined code called `LabelEncorder` to automatically do the assignment mapping for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select the categorical features that will be transformed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = df_census_income.select_dtypes(include=[object]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll call the `encoder.fit_transform()` function on each categorical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_columns = df_census_income[categorical_columns].apply(encoder.fit_transform)\n",
    "encoded_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call the encoder to fit transform each column manually. That way we can also see which feature categories are labelled as `0,..,n`\n",
    "\n",
    "Since we applied `fit_transform` using pandas' `apply` function, we can only get the last column it converted. The cell bellow shows what `0` and `1` mean for the `label` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(zip(encoder.classes_, range(0, len(encoder.classes_)+1)))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the all the categorical columns to have this newly transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the categorical columns to the new encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "\n",
    "\n",
    "df_census_income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate our features from our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X_census = None\n",
    "y_census = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, split our data into training and test data. Set the random state to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "X_train_census, X_test_census, y_train_census, y_test_census = None\n",
    "\n",
    "print(\"wine train and test split\")\n",
    "print(\"X_train_census: \", X_train_census.shape)\n",
    "print(\"y_train_census: \", y_train_census.shape)\n",
    "print(\"X_test_census: \", X_test_census.shape)\n",
    "print(\"y_test_census: \", y_test_census.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a simple decision tree classifier\n",
    "\n",
    "We'll train a decision tree first then compare its performance to the ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a decision tree with the default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "dtc = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run predictions on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_train = None\n",
    "\n",
    "predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be computing for the accuracy multiple times in this notebook, so let's create a function for this.\n",
    "\n",
    "`compute_accuracy()` will compute for the accuracy given two vectors of equal length\n",
    "\n",
    "__Inputs:__\n",
    "- `predictions`: A numpy array of shape `(N,)` consisting of `N` samples representing the predicted values\n",
    "- `actual`: A numpy array of shape `(N,)` consisting of `N` samples representing the actual (target) values\n",
    "\n",
    "__Outputs:__\n",
    "- `accuracy`: A scalar representing the percentage of elements where `predictions` and `actual` match out of the total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, actual):\n",
    "    # write code here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = compute_accuracy(predictions_train, y_train_census)\n",
    "\n",
    "print(\"Decision tree classifier train accuracy:\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The accuracy should be ~98%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_test = None\n",
    "\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = compute_accuracy(predictions_test, y_test_census)\n",
    "\n",
    "print(\"Decision tree classifier test accuracy:\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #9:__ What is the decision tree classifier's test accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the decision tree classifier's test accuracy?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a random forest classifier\n",
    "We will use the `sklearn.ensemble.RandomForestClssifier` library to make a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a random forest model with `300` base models. You can check out the other parameters in `RandomForestClassifier` and tweak it later. Set the random state to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "rfc = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_train = None\n",
    "\n",
    "predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = compute_accuracy(predictions_train, y_train_census)\n",
    "\n",
    "print(\"Random forest classifier train accuracy:\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest classifier's train accuracy should be lower than the decision tree classifier's train accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #10:** What will happen to the training accuracy if we have a lower number of base models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What will happen to the training accuracy if we have a lower number of base models?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try our random forest's performance on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_test = None\n",
    "\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = compute_accuracy(predictions_test, y_test_census)\n",
    "\n",
    "print(\"Random forest classifier test accuracy:\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare our random forest's accuracy compared to the decision tree's accuracy on the test set. The random forest should have a higher test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature importance.__ Get the feature importance detected by the random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "feature_importance = None\n",
    "\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sanity check:__ You should see a vector of length `13`, one for each of our features\n",
    "\n",
    "The following code will allow us to see the feature importance next to the feature name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rfc_importance = pd.DataFrame(data=feature_importance, index=df_census_income.drop([\"label\"], axis=1).columns, columns=[\"importance\"])\n",
    "df_rfc_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #11:__ What are the top 4 most discriminating features? Order them from most important to least important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What are the top 4 most discriminating features? Order them from most important to least important.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #12:__ What are the top 2 least discriminating features? Least important first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What are the top 2 least discriminating features? Least important first.-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #13:__ What can you, as a modeller, do with this list of feature importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What can you, as a modeller, do with this list of feature importance?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an adaboost classifier\n",
    "We can use the `sklearn.ensemble.AdaBoostClassifier` library to code our adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoostClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a adaboost model with `300` base models. You can check out the other parameters in `AdaBoostClassifier` and tweak it later. Set the random state to `42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n",
    "abc = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_train = None\n",
    "\n",
    "predictions_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = compute_accuracy(predictions_train, y_train_census)\n",
    "\n",
    "print(\"Adaboost classifier train accuracy:\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sanity check:** The accuracy should be ~87%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question #14:** What will happen to the train accuracy if our adaboost model has a lower number of base models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What will happen to the train accuracy if our adaboost model has a lower number of base models?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try our adaboost models's performance on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# write code here\n",
    "predictions_test = None\n",
    "\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = compute_accuracy(predictions_test, y_test_census)\n",
    "\n",
    "print(\"Adaboost classifier test accuracy:\", acc, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #15:__ What is the Adaboost classifier's test accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What is the Adaboost classifier's test accuracy?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #16:__ Why is it expected for the decision tree classifier to equal or outperform the ensemble models in terms of training performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: Why is it expected for the decision tree classifier to equal or outperform the ensemble models in terms of training performance?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #17:__ Why did both ensemble models outperform the decision tree classifier in terms of test performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: Why did both ensemble models outperform the decision tree classifier in terms of test performance?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's visualize one adaboost base model.** Get the fist base model from the Adaboost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = abc.estimators_[0]\n",
    "\n",
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='ab_classification_base_tree.dot', \n",
    "                feature_names = df_census_income.drop(columns=\"label\").columns,\n",
    "                class_names = encoder.classes_,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'ab_classification_base_tree.dot', '-o', 'ab_classification_base_tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'ab_classification_base_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can edit the .dot files to configure how the tree will be graphed.\n",
    "\n",
    "**Note:** You can also change the estimator index to select the base model you want to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #18:__ How will you describe the tree/chart above?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: How will you describe the tree/chart above?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question #19:__ What feature was used in the __first__ decision stump?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--crumb;qna;Question: What feature was used in the first decision stump?-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "* Ensemble models generally have a lower a training error than its overfit single decision tree counterparts\n",
    "\n",
    "* Their advantage of using ensemble models is its ability to lower the test (and validation) error through the way it \"manipulated\" the bias-variance decomposition\n",
    "\n",
    "* We did not make a new model, we just used a simple decision tree as our base models, and built a meta learning algorithm over it.\n",
    "\n",
    "* The benefits of using ensemble models may seem small right now, but the effect is clearer with more complex datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "  \n",
    "- Ron Kohavi (1996). Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid. In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>fin</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->\n",
    "\n",
    "<sup>made/compiled by daniel stanley tan & courtney anne ngo üê∞ & thomas james tiam-lee</sup> <br>\n",
    "<sup>for comments, corrections, suggestions, please email:</sup><sup> danieltan07@gmail.com & courtneyngo@gmail.com & thomasjamestiamlee@gmail.com</sup><br>\n",
    "<sup>please cc your instructor, too</sup>\n",
    "<!-- DO NOT MODIFY OR DELETE THIS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
